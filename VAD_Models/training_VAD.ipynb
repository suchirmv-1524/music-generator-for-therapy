{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "DvutsZ2QeujB",
        "outputId": "a795c8e7-e556-4240-f629-278b7a2e217f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9cece50c-a729-447f-a19b-67e5a87f7164\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9cece50c-a729-447f-a19b-67e5a87f7164\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving updated_iemocap_metadata.csv to updated_iemocap_metadata.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()  # Choose files from your system\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5nQf0IbfvOX",
        "outputId": "1bbfbbe0-dcf0-4c14-862a-10c07f327978"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data  updated_iemocap_metadata.csv\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlbFApechabk",
        "outputId": "50232f79-8cc4-4c27-b190-e5e9d1c507fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Updated CSV saved to: /content/sample_data/updated_iemocap_metadata_colab.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Step 1: Load the CSV\n",
        "csv_path = '/content/updated_iemocap_metadata.csv'\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Step 2: Update paths (from Kaggle path to Colab path)\n",
        "df['filepath'] = df['filepath'].str.replace(\n",
        "    '/kaggle/input/iemocap/iemocap_audio/', '/content/iemocap/', regex=False\n",
        ")\n",
        "\n",
        "# Step 3: Save the updated CSV\n",
        "updated_csv_path = '/content/sample_data/updated_iemocap_metadata_colab.csv'\n",
        "df.to_csv(updated_csv_path, index=False)\n",
        "\n",
        "print(f\"✅ Updated CSV saved to: {updated_csv_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijiH8c69h5NP",
        "outputId": "babb5415-6a6d-4503-c5d8-447c0a6e8eed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    /content/iemocap/Ses01F_impro01_F000.wav\n",
            "1    /content/iemocap/Ses01F_impro01_F001.wav\n",
            "2    /content/iemocap/Ses01F_impro01_F002.wav\n",
            "3    /content/iemocap/Ses01F_impro01_F003.wav\n",
            "4    /content/iemocap/Ses01F_impro01_F004.wav\n",
            "Name: filepath, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(df['filepath'].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqUVwK5niS7-",
        "outputId": "d7ac0a07-616b-45df-eefb-97648ba63061"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive not mounted, so nothing to flush and unmount.\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.flush_and_unmount()\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmv9t5TpuCNG",
        "outputId": "494de64a-f342-4b87-d979-b91a97c4501b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Unzipped to /content/iemocap/\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Set the path\n",
        "zip_path = '/content/drive/MyDrive/iemocap_audio.zip'\n",
        "extract_to = '/content/iemocap/'\n",
        "\n",
        "# Create target folder\n",
        "os.makedirs(extract_to, exist_ok=True)\n",
        "\n",
        "# Extract the zip\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n",
        "\n",
        "print(f\"✅ Unzipped to {extract_to}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import librosa\n",
        "from IPython.display import Audio\n",
        "\n",
        "# Load CSV\n",
        "csv_path = '/content/sample_data/updated_iemocap_metadata_colab.csv'\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Get the first audio file path\n",
        "audio_path = df['filepath'].iloc[0]\n",
        "\n",
        "# Load audio\n",
        "waveform, sr = librosa.load(audio_path, sr=None)\n",
        "\n",
        "# Play audio\n",
        "Audio(waveform, rate=sr)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "Vv1xb188BFfy",
        "outputId": "3d42c15c-d4a1-4bd9-c562-d2d119734f3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.Audio object>"
            ],
            "text/html": [
              "\n",
              "                <audio  controls=\"controls\" >\n",
              "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
              "                    Your browser does not support the audio element.\n",
              "                </audio>\n",
              "              "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Install dependencies\n",
        "!pip install numpy==1.26.4\n",
        "!pip install pandas==2.2.2\n",
        "!pip install torch==2.0.0 torchvision==0.15.1\n",
        "!pip install transformers==4.31.0\n",
        "!pip install torchaudio==2.0.1\n",
        "!pip install tqdm==4.66.2\n",
        "!pip install nlpaug==1.1.11"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yoi9Shh6DIOn",
        "outputId": "6cf7f9be-74ce-4750-b0da-6c4afc90203f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas==2.2.2 in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas==2.2.2) (1.17.0)\n",
            "Requirement already satisfied: torch==2.0.0 in /usr/local/lib/python3.11/dist-packages (2.0.0)\n",
            "Requirement already satisfied: torchvision==0.15.1 in /usr/local/lib/python3.11/dist-packages (0.15.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (4.13.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (2.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.1) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.1) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.1) (11.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (75.2.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (0.45.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.0) (3.31.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.0) (18.1.8)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.1) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.1) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.1) (2025.1.31)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.0) (1.3.0)\n",
            "Requirement already satisfied: transformers==4.31.0 in /usr/local/lib/python3.11/dist-packages (4.31.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.31.0) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.31.0) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.31.0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.31.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.31.0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.31.0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.31.0) (2.32.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.31.0) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.31.0) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.31.0) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.31.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.31.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.31.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.31.0) (2025.1.31)\n",
            "Requirement already satisfied: torchaudio==2.0.1 in /usr/local/lib/python3.11/dist-packages (2.0.1)\n",
            "Requirement already satisfied: torch==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torchaudio==2.0.1) (2.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchaudio==2.0.1) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchaudio==2.0.1) (4.13.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchaudio==2.0.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchaudio==2.0.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchaudio==2.0.1) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchaudio==2.0.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchaudio==2.0.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchaudio==2.0.1) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchaudio==2.0.1) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchaudio==2.0.1) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchaudio==2.0.1) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchaudio==2.0.1) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchaudio==2.0.1) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchaudio==2.0.1) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchaudio==2.0.1) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchaudio==2.0.1) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchaudio==2.0.1) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchaudio==2.0.1) (75.2.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchaudio==2.0.1) (0.45.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.0->torchaudio==2.0.1) (3.31.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.0->torchaudio==2.0.1) (18.1.8)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.0->torchaudio==2.0.1) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.0->torchaudio==2.0.1) (1.3.0)\n",
            "Requirement already satisfied: tqdm==4.66.2 in /usr/local/lib/python3.11/dist-packages (4.66.2)\n",
            "Requirement already satisfied: nlpaug==1.1.11 in /usr/local/lib/python3.11/dist-packages (1.1.11)\n",
            "Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.11/dist-packages (from nlpaug==1.1.11) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from nlpaug==1.1.11) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.11/dist-packages (from nlpaug==1.1.11) (2.32.3)\n",
            "Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from nlpaug==1.1.11) (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown>=4.0.0->nlpaug==1.1.11) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown>=4.0.0->nlpaug==1.1.11) (3.18.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown>=4.0.0->nlpaug==1.1.11) (4.66.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.0->nlpaug==1.1.11) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.0->nlpaug==1.1.11) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.0->nlpaug==1.1.11) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->nlpaug==1.1.11) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->nlpaug==1.1.11) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->nlpaug==1.1.11) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->nlpaug==1.1.11) (2025.1.31)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->nlpaug==1.1.11) (1.17.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug==1.1.11) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug==1.1.11) (4.13.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=4.0.0->nlpaug==1.1.11) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "import pandas\n",
        "import torch\n",
        "import transformers\n",
        "import torchaudio\n",
        "import tqdm\n",
        "import nlpaug\n",
        "print(f\"NumPy: {numpy.__version__}\")  # Should be 1.26.4\n",
        "print(f\"Pandas: {pandas.__version__}\")  # Should be 2.2.2\n",
        "print(f\"Torch: {torch.__version__}\")  # Should be 2.0.0\n",
        "print(f\"Transformers: {transformers.__version__}\")  # Should be 4.31.0\n",
        "print(f\"Torchaudio: {torchaudio.__version__}\")  # Should be 2.0.1\n",
        "print(f\"Tqdm: {tqdm.__version__}\")  # Should be 4.66.2\n",
        "print(f\"Nlpaug: {nlpaug.__version__}\")  # Should be 1.1.11\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")  # Should be True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DkVZBm6DRRW",
        "outputId": "f3a66b06-0557-40e3-f131-8b6609f23133"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy: 1.26.4\n",
            "Pandas: 2.2.2\n",
            "Torch: 2.0.0+cu117\n",
            "Transformers: 4.31.0\n",
            "Torchaudio: 2.0.1+cu117\n",
            "Tqdm: 4.66.2\n",
            "Nlpaug: 1.1.11\n",
            "CUDA available: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Initialize NLTK resources\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSnKHaXfDzXq",
        "outputId": "0ff75b2b-aa1c-4576-9ba3-4a76b6b079bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from transformers import HubertModel, Wav2Vec2FeatureExtractor, BertModel, BertTokenizer\n",
        "import torchaudio\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import nlpaug.augmenter.word as naw\n",
        "import random\n",
        "\n",
        "# Dataset with fixed augmentation\n",
        "class MultimodalIEMOCAPDataset(Dataset):\n",
        "    def __init__(self, csv_file, audio_feature_extractor, text_tokenizer, augment=True, max_audio_samples=128000):\n",
        "        self.df = pd.read_csv(csv_file)\n",
        "        self.audio_feature_extractor = audio_feature_extractor\n",
        "        self.text_tokenizer = text_tokenizer\n",
        "        self.augment = augment\n",
        "        self.text_augmenter = naw.SynonymAug(aug_p=0.3) if augment else None\n",
        "        self.max_audio_samples = max_audio_samples\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        audio_path = self.df.iloc[idx]['filepath']\n",
        "        transcript = self.df.iloc[idx]['transcription']\n",
        "        vad_label = self.df.iloc[idx]['EmoVal'].astype(np.float32)\n",
        "\n",
        "        if not os.path.exists(audio_path):\n",
        "            raise FileNotFoundError(f\"Audio file missing: {audio_path}\")\n",
        "\n",
        "        try:\n",
        "            audio, sr = torchaudio.load(audio_path)\n",
        "            if audio.abs().mean() < 1e-5:\n",
        "                raise ValueError(f\"Silent audio: {audio_path}\")\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Error loading audio {audio_path}: {str(e)}\")\n",
        "\n",
        "        if sr != 16000:\n",
        "            audio = torchaudio.transforms.Resample(sr, 16000)(audio)\n",
        "\n",
        "        audio = audio.squeeze(0)  # Remove channel dim if mono\n",
        "        if audio.dim() > 1:\n",
        "            audio = audio[0]  # Take first channel if stereo\n",
        "\n",
        "        # Pad or truncate to max_audio_samples\n",
        "        if audio.size(0) > self.max_audio_samples:\n",
        "            audio = audio[:self.max_audio_samples]\n",
        "        elif audio.size(0) < self.max_audio_samples:\n",
        "            audio = torch.nn.functional.pad(audio, (0, self.max_audio_samples - audio.size(0)))\n",
        "\n",
        "        if self.augment and random.random() < 0.5:\n",
        "            # Add noise\n",
        "            noise = torch.randn_like(audio) * 0.005\n",
        "            audio = audio + noise\n",
        "\n",
        "            # Speed augmentation\n",
        "            try:\n",
        "                speed_factor = random.uniform(0.9, 1.1)\n",
        "                effect = torch.tensor(audio).unsqueeze(0)  # [1, samples]\n",
        "                augmented_audio, new_sr = torchaudio.sox_effects.apply_effects_tensor(\n",
        "                    effect,\n",
        "                    sample_rate=16000,\n",
        "                    effects=[[\"speed\", str(speed_factor)], [\"rate\", \"16000\"]]\n",
        "                )\n",
        "                audio = augmented_audio.squeeze(0)\n",
        "                # Re-pad or truncate to max_audio_samples\n",
        "                if audio.size(0) > self.max_audio_samples:\n",
        "                    audio = audio[:self.max_audio_samples]\n",
        "                elif audio.size(0) < self.max_audio_samples:\n",
        "                    audio = torch.nn.functional.pad(audio, (0, self.max_audio_samples - audio.size(0)))\n",
        "            except Exception as e:\n",
        "                print(f\"Speed augmentation failed for {audio_path}: {e}\")\n",
        "                # Keep original audio\n",
        "\n",
        "        audio = audio.numpy()\n",
        "\n",
        "        if self.augment and self.text_augmenter and random.random() < 0.3:\n",
        "            try:\n",
        "                transcript = self.text_augmenter.augment(transcript)[0]\n",
        "            except Exception as e:\n",
        "                print(f\"Text augmentation failed for {audio_path}: {e}\")\n",
        "                # Keep original transcript\n",
        "\n",
        "        audio_inputs = self.audio_feature_extractor(\n",
        "            audio,\n",
        "            sampling_rate=16000,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=False,\n",
        "            truncation=False\n",
        "        )\n",
        "\n",
        "        text_inputs = self.text_tokenizer(\n",
        "            transcript,\n",
        "            padding=False,\n",
        "            truncation=True,\n",
        "            max_length=512,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'audio_values': audio_inputs['input_values'].squeeze(0),\n",
        "            'input_ids': text_inputs['input_ids'].squeeze(0),\n",
        "            'attention_mask': text_inputs['attention_mask'].squeeze(0)\n",
        "        }, torch.tensor(vad_label)\n",
        "\n",
        "# Dynamic collation\n",
        "def dynamic_collate_fn(batch):\n",
        "    inputs, labels = zip(*batch)\n",
        "    audio_values = [item['audio_values'] for item in inputs]\n",
        "    input_ids = [item['input_ids'] for item in inputs]\n",
        "    attention_masks = [item['attention_mask'] for item in inputs]\n",
        "\n",
        "    audio_values_padded = pad_sequence(audio_values, batch_first=True, padding_value=0.0)\n",
        "    input_ids_padded = pad_sequence(input_ids, batch_first=True, padding_value=0)\n",
        "    attention_masks_padded = pad_sequence(attention_masks, batch_first=True, padding_value=0)\n",
        "\n",
        "    labels_stacked = torch.stack(labels)\n",
        "\n",
        "    return {\n",
        "        'audio_values': audio_values_padded,\n",
        "        'input_ids': input_ids_padded,\n",
        "        'attention_mask': attention_masks_padded\n",
        "    }, labels_stacked\n",
        "\n",
        "# Label smoothing loss\n",
        "class SmoothMSELoss(nn.Module):\n",
        "    def __init__(self, smoothing=0.1):\n",
        "        super().__init__()\n",
        "        self.smoothing = smoothing\n",
        "        self.mse = nn.MSELoss()\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        smooth_target = target * (1 - self.smoothing) + 3.0 * self.smoothing\n",
        "        return self.mse(pred, smooth_target)\n",
        "\n",
        "# Transformer model\n",
        "class ValenceRegressor(nn.Module):\n",
        "    def __init__(self, audio_dim=768, text_dim=768, hidden_dim=192, num_heads=6, num_layers=2, dropout=0.5):\n",
        "        super().__init__()\n",
        "\n",
        "        self.audio_transformer = nn.ModuleList([\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=audio_dim,\n",
        "                nhead=num_heads,\n",
        "                dim_feedforward=hidden_dim * 4,\n",
        "                dropout=dropout,\n",
        "                batch_first=True\n",
        "            ) for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        self.audio_layer_norm = nn.LayerNorm(audio_dim)\n",
        "\n",
        "        self.audio_attention_pool = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim * 2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim * 2, 1)\n",
        "        )\n",
        "\n",
        "        self.text_encoder = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "        for param in self.text_encoder.parameters():\n",
        "            param.requires_grad = False\n",
        "        for param in list(self.text_encoder.parameters())[-2:]:\n",
        "            param.requires_grad = True\n",
        "\n",
        "        self.audio_projection = nn.Linear(audio_dim, hidden_dim)\n",
        "        self.text_projection = nn.Linear(text_dim, hidden_dim)\n",
        "\n",
        "        self.audio_to_text_attention = nn.MultiheadAttention(\n",
        "            embed_dim=hidden_dim,\n",
        "            num_heads=num_heads//2,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        self.text_to_audio_attention = nn.MultiheadAttention(\n",
        "            embed_dim=hidden_dim,\n",
        "            num_heads=num_heads//2,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        self.audio_gate = nn.Sequential(\n",
        "            nn.Linear(hidden_dim*2, hidden_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.text_gate = nn.Sequential(\n",
        "            nn.Linear(hidden_dim*2, hidden_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.fusion_layer = nn.Sequential(\n",
        "            nn.Linear(hidden_dim*2, hidden_dim*2),\n",
        "            nn.LayerNorm(hidden_dim*2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim*2, hidden_dim)\n",
        "        )\n",
        "\n",
        "        self.shared_fc = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "        self.output_branch = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim//2),\n",
        "            nn.LayerNorm(hidden_dim//2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout * 0.5),\n",
        "            nn.Linear(hidden_dim//2, 1)\n",
        "        )\n",
        "\n",
        "    def audio_attention_pooling(self, x, audio_mask=None):\n",
        "        weights = self.audio_attention_pool(x)\n",
        "        if audio_mask is not None:\n",
        "            weights = weights.masked_fill(~audio_mask.bool().unsqueeze(-1), float('-inf'))\n",
        "        weights = torch.softmax(weights, dim=1)\n",
        "        output = torch.bmm(weights.transpose(1, 2), x)\n",
        "        return output.squeeze(1)\n",
        "\n",
        "    def forward(self, audio_features, input_ids, attention_mask):\n",
        "        audio_mask = (audio_features.abs().sum(dim=-1) > 1e-6)\n",
        "\n",
        "        audio_repr = audio_features\n",
        "        for layer in self.audio_transformer:\n",
        "            audio_key_padding_mask = (~audio_mask).float()\n",
        "            audio_repr = layer(audio_repr, src_key_padding_mask=audio_key_padding_mask)\n",
        "\n",
        "        audio_repr = self.audio_layer_norm(audio_repr)\n",
        "\n",
        "        text_outputs = self.text_encoder(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "        )\n",
        "        text_repr = text_outputs.last_hidden_state\n",
        "\n",
        "        audio_proj = self.audio_projection(audio_repr)\n",
        "        text_proj = self.text_projection(text_repr)\n",
        "\n",
        "        audio_attended_text, _ = self.audio_to_text_attention(\n",
        "            query=audio_proj,\n",
        "            key=text_proj,\n",
        "            value=text_proj,\n",
        "            key_padding_mask=(1 - attention_mask).bool()\n",
        "        )\n",
        "\n",
        "        text_attended_audio, _ = self.text_to_audio_attention(\n",
        "            query=text_proj,\n",
        "            key=audio_proj,\n",
        "            value=audio_proj,\n",
        "            key_padding_mask=(~audio_mask).bool()\n",
        "        )\n",
        "\n",
        "        audio_concat = torch.cat([audio_proj, audio_attended_text], dim=-1)\n",
        "        text_concat = torch.cat([text_proj, text_attended_audio], dim=-1)\n",
        "\n",
        "        audio_gate_value = self.audio_gate(audio_concat)\n",
        "        text_gate_value = self.text_gate(text_concat)\n",
        "\n",
        "        gated_audio = audio_proj * audio_gate_value\n",
        "        gated_text = text_proj * text_gate_value\n",
        "\n",
        "        pooled_audio = self.audio_attention_pooling(gated_audio, audio_mask)\n",
        "        text_sum = torch.sum(gated_text * attention_mask.unsqueeze(-1), dim=1)\n",
        "        text_count = torch.sum(attention_mask, dim=1, keepdim=True).clamp(min=1)\n",
        "        pooled_text = text_sum / text_count\n",
        "\n",
        "        fused = torch.cat([pooled_audio, pooled_text], dim=1)\n",
        "        joint_repr = self.fusion_layer(fused)\n",
        "\n",
        "        shared = self.shared_fc(joint_repr)\n",
        "\n",
        "        output = self.output_branch(shared)\n",
        "        scaled_output = 1.0 + 4.0 * torch.sigmoid(output)\n",
        "\n",
        "        return scaled_output\n",
        "\n",
        "# Training function\n",
        "def train_valence_model(model, train_loader, val_loader, audio_model,\n",
        "                        num_epochs=15, lr=5e-5, max_norm=0.5):\n",
        "    device = torch.device(\"cuda\")\n",
        "    model = model.to(device)\n",
        "    audio_model = audio_model.to(device)\n",
        "\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-2)\n",
        "    criterion = SmoothMSELoss(smoothing=0.1)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "        optimizer, T_0=3, T_mult=2, eta_min=1e-6\n",
        "    )\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "    max_patience = 7\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        num_train_batches = 0\n",
        "\n",
        "        train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train Valence]\")\n",
        "\n",
        "        for batch_inputs, labels in train_pbar:\n",
        "            try:\n",
        "                audio_values = batch_inputs['audio_values'].to(device)\n",
        "                input_ids = batch_inputs['input_ids'].to(device)\n",
        "                attention_mask = batch_inputs['attention_mask'].to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    hubert_out = audio_model(audio_values).last_hidden_state\n",
        "                    hubert_out = hubert_out.detach()\n",
        "\n",
        "                outputs = model(hubert_out, input_ids, attention_mask)\n",
        "                loss = criterion(outputs.squeeze(), labels)\n",
        "\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
        "                optimizer.step()\n",
        "\n",
        "                train_loss += loss.item()\n",
        "                num_train_batches += 1\n",
        "\n",
        "                train_pbar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error in training batch: {e}\")\n",
        "                continue\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        if num_train_batches > 0:\n",
        "            train_loss /= num_train_batches\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        num_val_batches = 0\n",
        "\n",
        "        val_pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val Valence]\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_inputs, labels in val_pbar:\n",
        "                try:\n",
        "                    audio_values = batch_inputs['audio_values'].to(device)\n",
        "                    input_ids = batch_inputs['input_ids'].to(device)\n",
        "                    attention_mask = batch_inputs['attention_mask'].to(device)\n",
        "                    labels = labels.to(device)\n",
        "\n",
        "                    hubert_out = audio_model(audio_values).last_hidden_state\n",
        "\n",
        "                    outputs = model(hubert_out, input_ids, attention_mask)\n",
        "                    loss = criterion(outputs.squeeze(), labels)\n",
        "\n",
        "                    val_loss += loss.item()\n",
        "                    num_val_batches += 1\n",
        "\n",
        "                    val_pbar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error in validation batch: {e}\")\n",
        "                    continue\n",
        "\n",
        "        if num_val_batches > 0:\n",
        "            val_loss /= num_val_batches\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} [Valence] Results:\")\n",
        "        print(f\"  Train Loss: {train_loss:.4f}\")\n",
        "        print(f\"  Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), '/content/best_valence_regressor.pth')\n",
        "            print(f\"  Saved best model (val_loss: {val_loss:.4f})\")\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= max_patience:\n",
        "                print(f\"Early stopping after {epoch+1} epochs without improvement\")\n",
        "                break\n",
        "\n",
        "    return best_val_loss\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate_valence_model(model, test_loader, audio_model, device):\n",
        "    model.eval()\n",
        "    criterion = SmoothMSELoss(smoothing=0.1)\n",
        "    test_loss = 0.0\n",
        "    num_batches = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_inputs, labels in test_loader:\n",
        "            try:\n",
        "                audio_values = batch_inputs['audio_values'].to(device)\n",
        "                input_ids = batch_inputs['input_ids'].to(device)\n",
        "                attention_mask = batch_inputs['attention_mask'].to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                hubert_out = audio_model(audio_values).last_hidden_state\n",
        "\n",
        "                outputs = model(hubert_out, input_ids, attention_mask)\n",
        "                loss = criterion(outputs.squeeze(), labels)\n",
        "\n",
        "                test_loss += loss.item()\n",
        "                num_batches += 1\n",
        "\n",
        "                all_preds.append(outputs.squeeze().cpu().numpy())\n",
        "                all_labels.append(labels.cpu().numpy())\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error in test batch: {e}\")\n",
        "                continue\n",
        "\n",
        "    if num_batches > 0:\n",
        "        test_loss /= num_batches\n",
        "        all_preds = np.concatenate(all_preds)\n",
        "        all_labels = np.concatenate(all_labels)\n",
        "        from scipy.stats import pearsonr\n",
        "        pcc, _ = pearsonr(all_preds, all_labels)\n",
        "    else:\n",
        "        test_loss = float('inf')\n",
        "        pcc = 0.0\n",
        "\n",
        "    return test_loss, pcc\n",
        "\n",
        "# Main execution\n",
        "def main():\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    # Configuration\n",
        "    csv_file = \"/content/sample_data/updated_iemocap_metadata_colab.csv\"\n",
        "    audio_feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\"facebook/hubert-base-ls960\")\n",
        "    text_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "    hubert_model = HubertModel.from_pretrained(\"facebook/hubert-base-ls960\")\n",
        "    for param in hubert_model.parameters():\n",
        "        param.requires_grad = False\n",
        "    hubert_model.eval()\n",
        "    hubert_model = hubert_model.to(device)\n",
        "\n",
        "    # Dataset and loaders\n",
        "    train_dataset = MultimodalIEMOCAPDataset(\n",
        "        csv_file=csv_file,\n",
        "        audio_feature_extractor=audio_feature_extractor,\n",
        "        text_tokenizer=text_tokenizer,\n",
        "        augment=True,\n",
        "        max_audio_samples=128000\n",
        "    )\n",
        "    val_dataset = MultimodalIEMOCAPDataset(\n",
        "        csv_file=csv_file,\n",
        "        audio_feature_extractor=audio_feature_extractor,\n",
        "        text_tokenizer=text_tokenizer,\n",
        "        augment=False,\n",
        "        max_audio_samples=128000\n",
        "    )\n",
        "    test_dataset = MultimodalIEMOCAPDataset(\n",
        "        csv_file=csv_file,\n",
        "        audio_feature_extractor=audio_feature_extractor,\n",
        "        text_tokenizer=text_tokenizer,\n",
        "        augment=False,\n",
        "        max_audio_samples=128000\n",
        "    )\n",
        "\n",
        "    train_size = int(0.8 * len(train_dataset))\n",
        "    val_size = int(0.1 * len(train_dataset))\n",
        "    test_size = len(train_dataset) - train_size - val_size\n",
        "    train_dataset, _, _ = random_split(\n",
        "        train_dataset, [train_size, val_size, test_size],\n",
        "        generator=torch.Generator().manual_seed(42)\n",
        "    )\n",
        "    _, val_dataset, _ = random_split(\n",
        "        val_dataset, [train_size, val_size, test_size],\n",
        "        generator=torch.Generator().manual_seed(42)\n",
        "    )\n",
        "    _, _, test_dataset = random_split(\n",
        "        test_dataset, [train_size, val_size, test_size],\n",
        "        generator=torch.Generator().manual_seed(42)\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=8,\n",
        "        shuffle=True,\n",
        "        num_workers=0,\n",
        "        pin_memory=True,\n",
        "        collate_fn=dynamic_collate_fn\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=8,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        pin_memory=True,\n",
        "        collate_fn=dynamic_collate_fn\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=8,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        pin_memory=True,\n",
        "        collate_fn=dynamic_collate_fn\n",
        "    )\n",
        "\n",
        "    # Model\n",
        "    model = ValenceRegressor(\n",
        "        audio_dim=768,\n",
        "        text_dim=768,\n",
        "        hidden_dim=192,\n",
        "        num_heads=6,\n",
        "        num_layers=2,\n",
        "        dropout=0.5\n",
        "    ).to(device)\n",
        "\n",
        "    # Training\n",
        "    print(\"Training Valence model...\")\n",
        "    best_val_loss = train_valence_model(\n",
        "        model,\n",
        "        train_loader,\n",
        "        val_loader,\n",
        "        hubert_model,\n",
        "        num_epochs=15,\n",
        "        lr=5e-5,\n",
        "        max_norm=0.5\n",
        "    )\n",
        "\n",
        "    # Evaluation\n",
        "    model.load_state_dict(torch.load('/content/best_valence_regressor.pth'))\n",
        "    test_loss, test_pcc = evaluate_valence_model(model, test_loader, hubert_model, device)\n",
        "\n",
        "    print(\"\\nTest Results:\")\n",
        "    print(f\"  Valence MSE: {test_loss:.4f}\")\n",
        "    print(f\"  Valence PCC: {test_pcc:.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOGTmsNFE93H",
        "outputId": "4415559f-bc31-4ef1-846d-786483f647d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Valence model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/15 [Train Valence]:   0%|          | 0/1004 [00:00<?, ?it/s]<ipython-input-10-dde1b6da82b4>:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  effect = torch.tensor(audio).unsqueeze(0)  # [1, samples]\n",
            "Epoch 1/15 [Train Valence]: 100%|██████████| 1004/1004 [09:21<00:00,  1.79it/s, loss=0.9520]\n",
            "Epoch 1/15 [Val Valence]:   0%|          | 0/126 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:544: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)\n",
            "  return torch._transformer_encoder_layer_fwd(\n",
            "Epoch 1/15 [Val Valence]: 100%|██████████| 126/126 [00:45<00:00,  2.76it/s, loss=0.4118]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15 [Valence] Results:\n",
            "  Train Loss: 0.6754\n",
            "  Val Loss: 0.4813\n",
            "  Saved best model (val_loss: 0.4813)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/15 [Train Valence]: 100%|██████████| 1004/1004 [09:08<00:00,  1.83it/s, loss=0.3010]\n",
            "Epoch 2/15 [Val Valence]: 100%|██████████| 126/126 [00:44<00:00,  2.82it/s, loss=0.1743]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/15 [Valence] Results:\n",
            "  Train Loss: 0.4885\n",
            "  Val Loss: 0.3815\n",
            "  Saved best model (val_loss: 0.3815)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/15 [Train Valence]: 100%|██████████| 1004/1004 [09:10<00:00,  1.82it/s, loss=0.4766]\n",
            "Epoch 3/15 [Val Valence]: 100%|██████████| 126/126 [00:44<00:00,  2.83it/s, loss=0.0935]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/15 [Valence] Results:\n",
            "  Train Loss: 0.4110\n",
            "  Val Loss: 0.4085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/15 [Train Valence]: 100%|██████████| 1004/1004 [09:10<00:00,  1.82it/s, loss=0.2069]\n",
            "Epoch 4/15 [Val Valence]: 100%|██████████| 126/126 [00:44<00:00,  2.82it/s, loss=0.4076]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/15 [Valence] Results:\n",
            "  Train Loss: 0.4181\n",
            "  Val Loss: 0.4480\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/15 [Train Valence]: 100%|██████████| 1004/1004 [09:07<00:00,  1.83it/s, loss=0.6245]\n",
            "Epoch 5/15 [Val Valence]: 100%|██████████| 126/126 [00:44<00:00,  2.83it/s, loss=0.0390]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/15 [Valence] Results:\n",
            "  Train Loss: 0.3867\n",
            "  Val Loss: 0.3726\n",
            "  Saved best model (val_loss: 0.3726)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/15 [Train Valence]: 100%|██████████| 1004/1004 [09:10<00:00,  1.83it/s, loss=0.5646]\n",
            "Epoch 6/15 [Val Valence]: 100%|██████████| 126/126 [00:44<00:00,  2.82it/s, loss=0.2800]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/15 [Valence] Results:\n",
            "  Train Loss: 0.3553\n",
            "  Val Loss: 0.3403\n",
            "  Saved best model (val_loss: 0.3403)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/15 [Train Valence]: 100%|██████████| 1004/1004 [09:07<00:00,  1.83it/s, loss=0.1587]\n",
            "Epoch 7/15 [Val Valence]: 100%|██████████| 126/126 [00:44<00:00,  2.82it/s, loss=0.1156]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/15 [Valence] Results:\n",
            "  Train Loss: 0.3271\n",
            "  Val Loss: 0.3369\n",
            "  Saved best model (val_loss: 0.3369)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/15 [Train Valence]: 100%|██████████| 1004/1004 [09:07<00:00,  1.83it/s, loss=0.1090]\n",
            "Epoch 8/15 [Val Valence]: 100%|██████████| 126/126 [00:44<00:00,  2.84it/s, loss=0.1195]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/15 [Valence] Results:\n",
            "  Train Loss: 0.3029\n",
            "  Val Loss: 0.3290\n",
            "  Saved best model (val_loss: 0.3290)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/15 [Train Valence]: 100%|██████████| 1004/1004 [09:03<00:00,  1.85it/s, loss=0.2170]\n",
            "Epoch 9/15 [Val Valence]: 100%|██████████| 126/126 [00:44<00:00,  2.84it/s, loss=0.1045]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/15 [Valence] Results:\n",
            "  Train Loss: 0.2851\n",
            "  Val Loss: 0.3294\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/15 [Train Valence]: 100%|██████████| 1004/1004 [09:02<00:00,  1.85it/s, loss=0.4141]\n",
            "Epoch 10/15 [Val Valence]: 100%|██████████| 126/126 [00:44<00:00,  2.84it/s, loss=0.2042]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/15 [Valence] Results:\n",
            "  Train Loss: 0.3131\n",
            "  Val Loss: 0.3676\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/15 [Train Valence]: 100%|██████████| 1004/1004 [09:01<00:00,  1.85it/s, loss=0.1772]\n",
            "Epoch 11/15 [Val Valence]: 100%|██████████| 126/126 [00:44<00:00,  2.84it/s, loss=0.1814]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/15 [Valence] Results:\n",
            "  Train Loss: 0.2970\n",
            "  Val Loss: 0.3376\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/15 [Train Valence]: 100%|██████████| 1004/1004 [09:06<00:00,  1.84it/s, loss=0.1734]\n",
            "Epoch 12/15 [Val Valence]: 100%|██████████| 126/126 [00:44<00:00,  2.84it/s, loss=0.1563]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/15 [Valence] Results:\n",
            "  Train Loss: 0.2860\n",
            "  Val Loss: 0.3289\n",
            "  Saved best model (val_loss: 0.3289)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/15 [Train Valence]: 100%|██████████| 1004/1004 [09:06<00:00,  1.84it/s, loss=0.0873]\n",
            "Epoch 13/15 [Val Valence]: 100%|██████████| 126/126 [00:44<00:00,  2.84it/s, loss=0.0209]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/15 [Valence] Results:\n",
            "  Train Loss: 0.2726\n",
            "  Val Loss: 0.3717\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/15 [Train Valence]: 100%|██████████| 1004/1004 [09:00<00:00,  1.86it/s, loss=0.5535]\n",
            "Epoch 14/15 [Val Valence]: 100%|██████████| 126/126 [00:44<00:00,  2.84it/s, loss=0.0028]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/15 [Valence] Results:\n",
            "  Train Loss: 0.2543\n",
            "  Val Loss: 0.3121\n",
            "  Saved best model (val_loss: 0.3121)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/15 [Train Valence]:   1%|          | 8/1004 [00:04<07:50,  2.11it/s, loss=0.2920]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCYtnEAZIqmH",
        "outputId": "c60b0c36-7d92-4d11-e035-480627b38e83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "model_path = '/content/drive/MyDrive/best_valence_regressor_8.pth'\n",
        "model = torch.load(model_path, map_location='cpu')\n"
      ],
      "metadata": {
        "id": "YMglxJq0rgJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "from transformers import HubertModel, Wav2Vec2FeatureExtractor, BertModel, BertTokenizer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def predict_valence_from_csv(csv_file, row_idx, model_path, device='cpu'):\n",
        "    # Load the CSV file\n",
        "    df = pd.read_csv(csv_file)\n",
        "    if row_idx < 0 or row_idx >= len(df):\n",
        "        raise ValueError(f\"Row index {row_idx} is out of range [0, {len(df)-1}]\")\n",
        "\n",
        "    # Extract audio path and transcription from the specified row\n",
        "    audio_path = df.iloc[row_idx]['filepath']\n",
        "    transcription = df.iloc[row_idx]['transcription']\n",
        "    ground_truth_valence = df.iloc[row_idx]['EmoVal'].astype(np.float32)\n",
        "\n",
        "    # Load the trained model with map_location to CPU\n",
        "    device = torch.device(device)  # Force CPU since CUDA is unavailable\n",
        "    model = ValenceRegressor(audio_dim=768, text_dim=768, hidden_dim=192, num_heads=6, num_layers=2, dropout=0.5)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))  # Map to CPU\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # Load feature extractors and tokenizers\n",
        "    audio_feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\"facebook/hubert-base-ls960\")\n",
        "    text_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "    hubert_model = HubertModel.from_pretrained(\"facebook/hubert-base-ls960\")\n",
        "    hubert_model.eval()\n",
        "    hubert_model = hubert_model.to(device)\n",
        "    for param in hubert_model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # Load and preprocess audio\n",
        "    if not os.path.exists(audio_path):\n",
        "        raise FileNotFoundError(f\"Audio file missing: {audio_path}\")\n",
        "\n",
        "    try:\n",
        "        audio, sr = torchaudio.load(audio_path)\n",
        "        if audio.abs().mean() < 1e-5:\n",
        "            raise ValueError(f\"Silent audio: {audio_path}\")\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Error loading audio {audio_path}: {str(e)}\")\n",
        "\n",
        "    if sr != 16000:\n",
        "        audio = torchaudio.transforms.Resample(sr, 16000)(audio)\n",
        "\n",
        "    audio = audio.squeeze(0)  # Remove channel dim if mono\n",
        "    if audio.dim() > 1:\n",
        "        audio = audio[0]  # Take first channel if stereo\n",
        "\n",
        "    max_audio_samples = 128000\n",
        "    if audio.size(0) > max_audio_samples:\n",
        "        audio = audio[:max_audio_samples]\n",
        "    elif audio.size(0) < max_audio_samples:\n",
        "        audio = torch.nn.functional.pad(audio, (0, max_audio_samples - audio.size(0)))\n",
        "\n",
        "    audio = audio.numpy()\n",
        "    audio_inputs = audio_feature_extractor(\n",
        "        audio,\n",
        "        sampling_rate=16000,\n",
        "        return_tensors=\"pt\",\n",
        "        padding=False,\n",
        "        truncation=False\n",
        "    )\n",
        "    audio_values = audio_inputs['input_values'].to(device)\n",
        "\n",
        "    # Process transcription\n",
        "    text_inputs = text_tokenizer(\n",
        "        transcription,\n",
        "        padding=False,\n",
        "        truncation=True,\n",
        "        max_length=512,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    input_ids = text_inputs['input_ids'].to(device)\n",
        "    attention_mask = text_inputs['attention_mask'].to(device)\n",
        "\n",
        "    # Get features from Hubert model\n",
        "    with torch.no_grad():\n",
        "        hubert_out = hubert_model(audio_values).last_hidden_state\n",
        "\n",
        "    # Predict valence\n",
        "    with torch.no_grad():\n",
        "        output = model(hubert_out, input_ids, attention_mask)\n",
        "        predicted_valence = output.squeeze().item()  # Scale is 1.0 to 5.0\n",
        "\n",
        "    return predicted_valence, ground_truth_valence\n",
        "\n",
        "# Transformer model definition (same as in training code)\n",
        "class ValenceRegressor(nn.Module):\n",
        "    def __init__(self, audio_dim=768, text_dim=768, hidden_dim=192, num_heads=6, num_layers=2, dropout=0.5):\n",
        "        super().__init__()\n",
        "\n",
        "        self.audio_transformer = nn.ModuleList([\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=audio_dim,\n",
        "                nhead=num_heads,\n",
        "                dim_feedforward=hidden_dim * 4,\n",
        "                dropout=dropout,\n",
        "                batch_first=True\n",
        "            ) for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        self.audio_layer_norm = nn.LayerNorm(audio_dim)\n",
        "\n",
        "        self.audio_attention_pool = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim * 2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim * 2, 1)\n",
        "        )\n",
        "\n",
        "        self.text_encoder = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "        for param in self.text_encoder.parameters():\n",
        "            param.requires_grad = False\n",
        "        for param in list(self.text_encoder.parameters())[-2:]:\n",
        "            param.requires_grad = True\n",
        "\n",
        "        self.audio_projection = nn.Linear(audio_dim, hidden_dim)\n",
        "        self.text_projection = nn.Linear(text_dim, hidden_dim)\n",
        "\n",
        "        self.audio_to_text_attention = nn.MultiheadAttention(\n",
        "            embed_dim=hidden_dim,\n",
        "            num_heads=num_heads//2,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        self.text_to_audio_attention = nn.MultiheadAttention(\n",
        "            embed_dim=hidden_dim,\n",
        "            num_heads=num_heads//2,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        self.audio_gate = nn.Sequential(\n",
        "            nn.Linear(hidden_dim*2, hidden_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.text_gate = nn.Sequential(\n",
        "            nn.Linear(hidden_dim*2, hidden_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.fusion_layer = nn.Sequential(\n",
        "            nn.Linear(hidden_dim*2, hidden_dim*2),\n",
        "            nn.LayerNorm(hidden_dim*2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim*2, hidden_dim)\n",
        "        )\n",
        "\n",
        "        self.shared_fc = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "        self.output_branch = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim//2),\n",
        "            nn.LayerNorm(hidden_dim//2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout * 0.5),\n",
        "            nn.Linear(hidden_dim//2, 1)\n",
        "        )\n",
        "\n",
        "    def audio_attention_pooling(self, x, audio_mask=None):\n",
        "        weights = self.audio_attention_pool(x)\n",
        "        if audio_mask is not None:\n",
        "            weights = weights.masked_fill(~audio_mask.bool().unsqueeze(-1), float('-inf'))\n",
        "        weights = torch.softmax(weights, dim=1)\n",
        "        output = torch.bmm(weights.transpose(1, 2), x)\n",
        "        return output.squeeze(1)\n",
        "\n",
        "    def forward(self, audio_features, input_ids, attention_mask):\n",
        "        audio_mask = (audio_features.abs().sum(dim=-1) > 1e-6)\n",
        "\n",
        "        audio_repr = audio_features\n",
        "        for layer in self.audio_transformer:\n",
        "            audio_key_padding_mask = (~audio_mask).float()\n",
        "            audio_repr = layer(audio_repr, src_key_padding_mask=audio_key_padding_mask)\n",
        "\n",
        "        audio_repr = self.audio_layer_norm(audio_repr)\n",
        "\n",
        "        text_outputs = self.text_encoder(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "        )\n",
        "        text_repr = text_outputs.last_hidden_state\n",
        "\n",
        "        audio_proj = self.audio_projection(audio_repr)\n",
        "        text_proj = self.text_projection(text_repr)\n",
        "\n",
        "        audio_attended_text, _ = self.audio_to_text_attention(\n",
        "            query=audio_proj,\n",
        "            key=text_proj,\n",
        "            value=text_proj,\n",
        "            key_padding_mask=(1 - attention_mask).bool()\n",
        "        )\n",
        "\n",
        "        text_attended_audio, _ = self.text_to_audio_attention(\n",
        "            query=text_proj,\n",
        "            key=audio_proj,\n",
        "            value=audio_proj,\n",
        "            key_padding_mask=(~audio_mask).bool()\n",
        "        )\n",
        "\n",
        "        audio_concat = torch.cat([audio_proj, audio_attended_text], dim=-1)\n",
        "        text_concat = torch.cat([text_proj, text_attended_audio], dim=-1)\n",
        "\n",
        "        audio_gate_value = self.audio_gate(audio_concat)\n",
        "        text_gate_value = self.text_gate(text_concat)\n",
        "\n",
        "        gated_audio = audio_proj * audio_gate_value\n",
        "        gated_text = text_proj * text_gate_value\n",
        "\n",
        "        pooled_audio = self.audio_attention_pooling(gated_audio, audio_mask)\n",
        "        text_sum = torch.sum(gated_text * attention_mask.unsqueeze(-1), dim=1)\n",
        "        text_count = torch.sum(attention_mask, dim=1, keepdim=True).clamp(min=1)\n",
        "        pooled_text = text_sum / text_count\n",
        "\n",
        "        fused = torch.cat([pooled_audio, pooled_text], dim=1)\n",
        "        joint_repr = self.fusion_layer(fused)\n",
        "\n",
        "        shared = self.shared_fc(joint_repr)\n",
        "\n",
        "        output = self.output_branch(shared)\n",
        "        scaled_output = 1.0 + 4.0 * torch.sigmoid(output)\n",
        "\n",
        "        return scaled_output\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Edit these paths and row index\n",
        "    csv_file = \"/content/sample_data/updated_iemocap_metadata_colab.csv\"\n",
        "    row_idx = 10021  # Change to desired row number\n",
        "    model_path = \"/content/drive/MyDrive/best_valence_regressor_8.pth\"\n",
        "\n",
        "    predicted_valence, ground_truth_valence = predict_valence_from_csv(csv_file, row_idx, model_path)\n",
        "    print(f\"Predicted Valence Score: {predicted_valence:.4f}\")\n",
        "    print(f\"Ground Truth Valence: {ground_truth_valence:.4f}\")"
      ],
      "metadata": {
        "id": "I-_xQUPjKZ9T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cbdf8fa-fb38-4a54-d456-bb7842da37f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:544: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)\n",
            "  return torch._transformer_encoder_layer_fwd(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Valence Score: 1.7735\n",
            "Ground Truth Valence: 1.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from transformers import HubertModel, Wav2Vec2FeatureExtractor, BertModel, BertTokenizer, get_linear_schedule_with_warmup\n",
        "import torchaudio\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import nlpaug.augmenter.word as naw\n",
        "import random\n",
        "\n",
        "# Dataset with fixed tensor copy\n",
        "class MultimodalIEMOCAPDataset(Dataset):\n",
        "    def __init__(self, csv_file, audio_feature_extractor, text_tokenizer, augment=True, max_audio_samples=128000):\n",
        "        self.df = pd.read_csv(csv_file)\n",
        "        self.audio_feature_extractor = audio_feature_extractor\n",
        "        self.text_tokenizer = text_tokenizer\n",
        "        self.augment = augment\n",
        "        self.text_augmenter = naw.SynonymAug(aug_p=0.3) if augment else None\n",
        "        self.max_audio_samples = max_audio_samples\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        audio_path = self.df.iloc[idx]['filepath']\n",
        "        transcript = self.df.iloc[idx]['transcription']\n",
        "\n",
        "        # Get both arousal and dominance labels\n",
        "        arousal_label = self.df.iloc[idx]['EmoAct'].astype(np.float32)\n",
        "        dominance_label = self.df.iloc[idx]['EmoDom'].astype(np.float32)\n",
        "\n",
        "        if not os.path.exists(audio_path):\n",
        "            raise FileNotFoundError(f\"Audio file missing: {audio_path}\")\n",
        "\n",
        "        try:\n",
        "            audio, sr = torchaudio.load(audio_path)\n",
        "            if audio.abs().mean() < 1e-5:\n",
        "                raise ValueError(f\"Silent audio: {audio_path}\")\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Error loading audio {audio_path}: {str(e)}\")\n",
        "\n",
        "        if sr != 16000:\n",
        "            audio = torchaudio.transforms.Resample(sr, 16000)(audio)\n",
        "\n",
        "        audio = audio.squeeze(0)  # Remove channel dim if mono\n",
        "        if audio.dim() > 1:\n",
        "            audio = audio[0]  # Take first channel if stereo\n",
        "\n",
        "        # Pad or truncate to max_audio_samples\n",
        "        if audio.size(0) > self.max_audio_samples:\n",
        "            audio = audio[:self.max_audio_samples]\n",
        "        elif audio.size(0) < self.max_audio_samples:\n",
        "            audio = torch.nn.functional.pad(audio, (0, self.max_audio_samples - audio.size(0)))\n",
        "\n",
        "        if self.augment and random.random() < 0.5:\n",
        "            # Add noise\n",
        "            noise = torch.randn_like(audio) * 0.005\n",
        "            audio = audio + noise\n",
        "\n",
        "            # Speed augmentation\n",
        "            try:\n",
        "                speed_factor = random.uniform(0.9, 1.1)\n",
        "                effect = audio.clone().detach().unsqueeze(0)  # [1, samples]\n",
        "                augmented_audio, new_sr = torchaudio.sox_effects.apply_effects_tensor(\n",
        "                    effect,\n",
        "                    sample_rate=16000,\n",
        "                    effects=[[\"speed\", str(speed_factor)], [\"rate\", \"16000\"]]\n",
        "                )\n",
        "                audio = augmented_audio.squeeze(0)\n",
        "                # Re-pad or truncate to max_audio_samples\n",
        "                if audio.size(0) > self.max_audio_samples:\n",
        "                    audio = audio[:self.max_audio_samples]\n",
        "                elif audio.size(0) < self.max_audio_samples:\n",
        "                    audio = torch.nn.functional.pad(audio, (0, self.max_audio_samples - audio.size(0)))\n",
        "            except Exception as e:\n",
        "                print(f\"Speed augmentation failed for {audio_path}: {e}\")\n",
        "                # Keep original audio\n",
        "\n",
        "        audio = audio.numpy()\n",
        "\n",
        "        if self.augment and self.text_augmenter and random.random() < 0.3:\n",
        "            try:\n",
        "                transcript = self.text_augmenter.augment(transcript)[0]\n",
        "            except Exception as e:\n",
        "                print(f\"Text augmentation failed for {audio_path}: {e}\")\n",
        "                # Keep original transcript\n",
        "\n",
        "        audio_inputs = self.audio_feature_extractor(\n",
        "            audio,\n",
        "            sampling_rate=16000,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=False,\n",
        "            truncation=False\n",
        "        )\n",
        "\n",
        "        text_inputs = self.text_tokenizer(\n",
        "            transcript,\n",
        "            padding=False,\n",
        "            truncation=True,\n",
        "            max_length=512,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'audio_values': audio_inputs['input_values'].squeeze(0),\n",
        "            'input_ids': text_inputs['input_ids'].squeeze(0),\n",
        "            'attention_mask': text_inputs['attention_mask'].squeeze(0)\n",
        "        }, {\n",
        "            'arousal': torch.tensor(arousal_label),\n",
        "            'dominance': torch.tensor(dominance_label)\n",
        "        }\n",
        "\n",
        "# Dynamic collation\n",
        "def dynamic_collate_fn(batch):\n",
        "    inputs, labels = zip(*batch)\n",
        "    audio_values = [item['audio_values'] for item in inputs]\n",
        "    input_ids = [item['input_ids'] for item in inputs]\n",
        "    attention_masks = [item['attention_mask'] for item in inputs]\n",
        "\n",
        "    audio_values_padded = pad_sequence(audio_values, batch_first=True, padding_value=0.0)\n",
        "    input_ids_padded = pad_sequence(input_ids, batch_first=True, padding_value=0)\n",
        "    attention_masks_padded = pad_sequence(attention_masks, batch_first=True, padding_value=0)\n",
        "\n",
        "    arousal_labels = torch.stack([item['arousal'] for item in labels])\n",
        "    dominance_labels = torch.stack([item['dominance'] for item in labels])\n",
        "\n",
        "    return {\n",
        "        'audio_values': audio_values_padded,\n",
        "        'input_ids': input_ids_padded,\n",
        "        'attention_mask': attention_masks_padded\n",
        "    }, {\n",
        "        'arousal': arousal_labels,\n",
        "        'dominance': dominance_labels\n",
        "    }\n",
        "\n",
        "# MultimodalArousalDominanceModel with fixed audio_attention_pool\n",
        "class MultimodalArousalDominanceModel(nn.Module):\n",
        "    def __init__(self, audio_dim=768, text_dim=768, hidden_dim=192, num_heads=6, num_layers=2, dropout=0.5):\n",
        "        super().__init__()\n",
        "\n",
        "        self.audio_transformer = nn.ModuleList([\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=audio_dim,\n",
        "                nhead=num_heads,\n",
        "                dim_feedforward=hidden_dim * 4,\n",
        "                dropout=dropout,\n",
        "                batch_first=True\n",
        "            ) for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        self.audio_layer_norm = nn.LayerNorm(audio_dim)\n",
        "\n",
        "        # Fixed input dimension to hidden_dim\n",
        "        self.audio_attention_pool = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim * 2),  # 192 -> 384\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim * 2, 1)  # 384 -> 1\n",
        "        )\n",
        "\n",
        "        self.text_encoder = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "        for param in self.text_encoder.parameters():\n",
        "            param.requires_grad = False\n",
        "        for param in list(self.text_encoder.parameters())[-2:]:\n",
        "            param.requires_grad = True\n",
        "\n",
        "        self.audio_projection = nn.Linear(audio_dim, hidden_dim)\n",
        "        self.text_projection = nn.Linear(text_dim, hidden_dim)\n",
        "\n",
        "        self.audio_to_text_attention = nn.MultiheadAttention(\n",
        "            embed_dim=hidden_dim,\n",
        "            num_heads=num_heads//2,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        self.text_to_audio_attention = nn.MultiheadAttention(\n",
        "            embed_dim=hidden_dim,\n",
        "            num_heads=num_heads//2,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        self.audio_gate = nn.Sequential(\n",
        "            nn.Linear(hidden_dim*2, hidden_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.text_gate = nn.Sequential(\n",
        "            nn.Linear(hidden_dim*2, hidden_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        # Task-Specific Fusion Layers\n",
        "        self.fusion_layer_arousal = nn.Sequential(\n",
        "            nn.Linear(hidden_dim*2, hidden_dim*2),\n",
        "            nn.LayerNorm(hidden_dim*2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim*2, hidden_dim)\n",
        "        )\n",
        "\n",
        "        self.fusion_layer_dominance = nn.Sequential(\n",
        "            nn.Linear(hidden_dim*2, hidden_dim*2),\n",
        "            nn.LayerNorm(hidden_dim*2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim*2, hidden_dim)\n",
        "        )\n",
        "\n",
        "        # Task-Specific FC Layers\n",
        "        self.shared_fc_arousal = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "        self.shared_fc_dominance = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "        # Task-Specific Output Branches\n",
        "        self.output_branch_arousal = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim//2),\n",
        "            nn.LayerNorm(hidden_dim//2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout * 0.5),\n",
        "            nn.Linear(hidden_dim//2, 1)\n",
        "        )\n",
        "\n",
        "        self.output_branch_dominance = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim//2),\n",
        "            nn.LayerNorm(hidden_dim//2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout * 0.5),\n",
        "            nn.Linear(hidden_dim//2, 1)\n",
        "        )\n",
        "\n",
        "    def audio_attention_pooling(self, x, audio_mask=None):\n",
        "        weights = self.audio_attention_pool(x)\n",
        "        if audio_mask is not None:\n",
        "            weights = weights.masked_fill(~audio_mask.bool().unsqueeze(-1), float('-inf'))\n",
        "        weights = torch.softmax(weights, dim=1)\n",
        "        output = torch.bmm(weights.transpose(1, 2), x)\n",
        "        return output.squeeze(1)\n",
        "\n",
        "    def forward(self, audio_features, input_ids, attention_mask):\n",
        "        audio_mask = (audio_features.abs().sum(dim=-1) > 1e-6)\n",
        "\n",
        "        audio_repr = audio_features\n",
        "        for layer in self.audio_transformer:\n",
        "            audio_key_padding_mask = (~audio_mask).float()\n",
        "            audio_repr = layer(audio_repr, src_key_padding_mask=audio_key_padding_mask)\n",
        "\n",
        "        audio_repr = self.audio_layer_norm(audio_repr)\n",
        "\n",
        "        text_outputs = self.text_encoder(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "        )\n",
        "        text_repr = text_outputs.last_hidden_state\n",
        "\n",
        "        audio_proj = self.audio_projection(audio_repr)\n",
        "        text_proj = self.text_projection(text_repr)\n",
        "\n",
        "        audio_attended_text, _ = self.audio_to_text_attention(\n",
        "            query=audio_proj,\n",
        "            key=text_proj,\n",
        "            value=text_proj,\n",
        "            key_padding_mask=(1 - attention_mask).bool()\n",
        "        )\n",
        "\n",
        "        text_attended_audio, _ = self.text_to_audio_attention(\n",
        "            query=text_proj,\n",
        "            key=audio_proj,\n",
        "            value=audio_proj,\n",
        "            key_padding_mask=(~audio_mask).bool()\n",
        "        )\n",
        "\n",
        "        audio_concat = torch.cat([audio_proj, audio_attended_text], dim=-1)\n",
        "        text_concat = torch.cat([text_proj, text_attended_audio], dim=-1)\n",
        "\n",
        "        audio_gate_value = self.audio_gate(audio_concat)\n",
        "        text_gate_value = self.text_gate(text_concat)\n",
        "\n",
        "        gated_audio = audio_proj * audio_gate_value\n",
        "        gated_text = text_proj * text_gate_value\n",
        "\n",
        "        pooled_audio = self.audio_attention_pooling(gated_audio, audio_mask)\n",
        "        text_sum = torch.sum(gated_text * attention_mask.unsqueeze(-1), dim=1)\n",
        "        text_count = torch.sum(attention_mask, dim=1, keepdim=True).clamp(min=1)\n",
        "        pooled_text = text_sum / text_count\n",
        "\n",
        "        fused = torch.cat([pooled_audio, pooled_text], dim=1)\n",
        "\n",
        "        # Task-Specific Processing\n",
        "        joint_repr_arousal = self.fusion_layer_arousal(fused)\n",
        "        joint_repr_dominance = self.fusion_layer_dominance(fused)\n",
        "\n",
        "        shared_arousal = self.shared_fc_arousal(joint_repr_arousal)\n",
        "        shared_dominance = self.shared_fc_dominance(joint_repr_dominance)\n",
        "\n",
        "        output_arousal = self.output_branch_arousal(shared_arousal)\n",
        "        output_dominance = self.output_branch_dominance(shared_dominance)\n",
        "\n",
        "        # Scale outputs to [1, 5]\n",
        "        scaled_arousal = 1.0 + 4.0 * torch.sigmoid(output_arousal)\n",
        "        scaled_dominance = 1.0 + 4.0 * torch.sigmoid(output_dominance)\n",
        "\n",
        "        return scaled_arousal, scaled_dominance\n",
        "\n",
        "# Training function with backpropagation optimizations\n",
        "def train_emotion_model(model, train_loader, val_loader, audio_model, num_epochs=15, lr=5e-5, max_norm=1.0):\n",
        "    device = torch.device(\"cuda\")\n",
        "    model = model.to(device)\n",
        "    audio_model = audio_model.to(device)\n",
        "\n",
        "    # Differential learning rates\n",
        "    optimizer = optim.AdamW([\n",
        "        {\"params\": model.text_encoder.parameters(), \"lr\": 5e-6},\n",
        "        {\"params\": [p for n, p in model.named_parameters() if \"dominance\" in n], \"lr\": 1e-4},  # Higher for dominance\n",
        "        {\"params\": [p for n, p in model.named_parameters() if \"text_encoder\" not in n and \"dominance\" not in n], \"lr\": lr}\n",
        "    ], weight_decay=1e-2)\n",
        "\n",
        "    criterion = nn.HuberLoss()  # Robust to outliers\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "        optimizer, T_0=3, T_mult=2, eta_min=1e-6\n",
        "    )\n",
        "    warmup_scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=500, num_training_steps=len(train_loader) * num_epochs)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "    max_patience = 10\n",
        "    arousal_weight = 1.0\n",
        "    dominance_weight = 1.0\n",
        "    accumulation_steps = 2\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_arousal_loss = 0.0\n",
        "        train_dominance_loss = 0.0\n",
        "        num_train_batches = 0\n",
        "\n",
        "        train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\")\n",
        "\n",
        "        for i, (batch_inputs, labels) in enumerate(train_pbar):\n",
        "            try:\n",
        "                audio_values = batch_inputs['audio_values'].to(device)\n",
        "                input_ids = batch_inputs['input_ids'].to(device)\n",
        "                attention_mask = batch_inputs['attention_mask'].to(device)\n",
        "                arousal_labels = labels['arousal'].to(device)\n",
        "                dominance_labels = labels['dominance'].to(device)\n",
        "\n",
        "                optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    hubert_out = audio_model(audio_values).last_hidden_state\n",
        "\n",
        "                arousal_outputs, dominance_outputs = model(hubert_out, input_ids, attention_mask)\n",
        "\n",
        "                arousal_loss = criterion(arousal_outputs.squeeze(), arousal_labels)\n",
        "                dominance_loss = criterion(dominance_outputs.squeeze(), dominance_labels)\n",
        "\n",
        "                total_loss = (arousal_weight * arousal_loss + dominance_weight * dominance_loss) / accumulation_steps\n",
        "\n",
        "                total_loss.backward()\n",
        "\n",
        "                if (i + 1) % accumulation_steps == 0:\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
        "                    optimizer.step()\n",
        "                    optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "                # Monitor gradients every 100 batches\n",
        "                if i % 100 == 0:\n",
        "                    for name, param in model.named_parameters():\n",
        "                        if param.grad is not None and (\"arousal\" in name or \"dominance\" in name):\n",
        "                            print(f\"{name}: Grad Norm = {param.grad.norm().item():.4f}\")\n",
        "\n",
        "                # Warmup for first 500 steps, then cosine annealing\n",
        "                if i + epoch * len(train_loader) < 500:\n",
        "                    warmup_scheduler.step()\n",
        "                else:\n",
        "                    scheduler.step()\n",
        "\n",
        "                train_loss += total_loss.item() * accumulation_steps\n",
        "                train_arousal_loss += arousal_loss.item()\n",
        "                train_dominance_loss += dominance_loss.item()\n",
        "                num_train_batches += 1\n",
        "\n",
        "                train_pbar.set_postfix({\n",
        "                    'loss': f\"{total_loss.item() * accumulation_steps:.4f}\",\n",
        "                    'a_loss': f\"{arousal_loss.item():.4f}\",\n",
        "                    'd_loss': f\"{dominance_loss.item():.4f}\"\n",
        "                })\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error in training batch: {e}\")\n",
        "                continue\n",
        "\n",
        "        if num_train_batches > 0:\n",
        "            train_loss /= num_train_batches\n",
        "            train_arousal_loss /= num_train_batches\n",
        "            train_dominance_loss /= num_train_batches\n",
        "\n",
        "            # Fixed and enhanced dynamic weighting\n",
        "            total_task_loss = train_arousal_loss + train_dominance_loss\n",
        "            if total_task_loss > 0:\n",
        "                arousal_weight = 0.5 * (train_arousal_loss / total_task_loss)\n",
        "                dominance_weight = 0.5 * (train_dominance_loss / total_task_loss)\n",
        "                if train_dominance_loss > train_arousal_loss * 1.2:\n",
        "                    dominance_weight *= 1.5\n",
        "                    arousal_weight *= 0.5\n",
        "                total_weight = arousal_weight + dominance_weight\n",
        "                arousal_weight /= total_weight\n",
        "                dominance_weight /= total_weight\n",
        "                arousal_weight = max(0.25, min(0.75, arousal_weight))\n",
        "                dominance_weight = max(0.25, min(0.75, dominance_weight))\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_arousal_loss = 0.0\n",
        "        val_dominance_loss = 0.0\n",
        "        num_val_batches = 0\n",
        "\n",
        "        val_pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_inputs, labels in val_pbar:\n",
        "                try:\n",
        "                    audio_values = batch_inputs['audio_values'].to(device)\n",
        "                    input_ids = batch_inputs['input_ids'].to(device)\n",
        "                    attention_mask = batch_inputs['attention_mask'].to(device)\n",
        "                    arousal_labels = labels['arousal'].to(device)\n",
        "                    dominance_labels = labels['dominance'].to(device)\n",
        "\n",
        "                    hubert_out = audio_model(audio_values).last_hidden_state\n",
        "\n",
        "                    arousal_outputs, dominance_outputs = model(hubert_out, input_ids, attention_mask)\n",
        "\n",
        "                    arousal_loss = criterion(arousal_outputs.squeeze(), arousal_labels)\n",
        "                    dominance_loss = criterion(dominance_outputs.squeeze(), dominance_labels)\n",
        "                    total_loss = 0.5 * arousal_loss + 0.5 * dominance_loss\n",
        "\n",
        "                    val_loss += total_loss.item()\n",
        "                    val_arousal_loss += arousal_loss.item()\n",
        "                    val_dominance_loss += dominance_loss.item()\n",
        "                    num_val_batches += 1\n",
        "\n",
        "                    val_pbar.set_postfix({\n",
        "                        'loss': f\"{total_loss.item():.4f}\",\n",
        "                        'a_loss': f\"{arousal_loss.item():.4f}\",\n",
        "                        'd_loss': f\"{dominance_loss.item():.4f}\"\n",
        "                    })\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error in validation batch: {e}\")\n",
        "                    continue\n",
        "\n",
        "        if num_val_batches > 0:\n",
        "            val_loss /= num_val_batches\n",
        "            val_arousal_loss /= num_val_batches\n",
        "            val_dominance_loss /= num_val_batches\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} Results:\")\n",
        "        print(f\"  Train Loss: {train_loss:.4f} (Arousal: {train_arousal_loss:.4f}, Dominance: {train_dominance_loss:.4f})\")\n",
        "        print(f\"  Val Loss: {val_loss:.4f} (Arousal: {val_arousal_loss:.4f}, Dominance: {val_dominance_loss:.4f})\")\n",
        "        print(f\"  Loss Weights - Arousal: {arousal_weight:.4f}, Dominance: {dominance_weight:.4f}\")\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), '/content/best_arousal_dominance_model.pth')\n",
        "            print(f\"  Saved best model (val_loss: {val_loss:.4f})\")\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= max_patience:\n",
        "                print(f\"Early stopping after {epoch+1} epochs without improvement\")\n",
        "                break\n",
        "\n",
        "    return best_val_loss\n",
        "\n",
        "# Evaluation function (completed)\n",
        "def evaluate_emotion_model(model, test_loader, audio_model, device):\n",
        "    model.eval()\n",
        "    criterion = nn.HuberLoss()\n",
        "    test_loss = 0.0\n",
        "    test_arousal_loss = 0.0\n",
        "    test_dominance_loss = 0.0\n",
        "    num_batches = 0\n",
        "\n",
        "    all_arousal_preds = []\n",
        "    all_arousal_labels = []\n",
        "    all_dominance_preds = []\n",
        "    all_dominance_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_inputs, labels in test_loader:\n",
        "            try:\n",
        "                audio_values = batch_inputs['audio_values'].to(device)\n",
        "                input_ids = batch_inputs['input_ids'].to(device)\n",
        "                attention_mask = batch_inputs['attention_mask'].to(device)\n",
        "                arousal_labels = labels['arousal'].to(device)\n",
        "                dominance_labels = labels['dominance'].to(device)\n",
        "\n",
        "                hubert_out = audio_model(audio_values).last_hidden_state\n",
        "\n",
        "                arousal_outputs, dominance_outputs = model(hubert_out, input_ids, attention_mask)\n",
        "\n",
        "                arousal_loss = criterion(arousal_outputs.squeeze(), arousal_labels)\n",
        "                dominance_loss = criterion(dominance_outputs.squeeze(), dominance_labels)\n",
        "\n",
        "                total_loss = 0.5 * arousal_loss + 0.5 * dominance_loss\n",
        "\n",
        "                test_loss += total_loss.item()\n",
        "                test_arousal_loss += arousal_loss.item()\n",
        "                test_dominance_loss += dominance_loss.item()\n",
        "                num_batches += 1\n",
        "\n",
        "                all_arousal_preds.append(arousal_outputs.squeeze().cpu().numpy())\n",
        "                all_arousal_labels.append(arousal_labels.cpu().numpy())\n",
        "                all_dominance_preds.append(dominance_outputs.squeeze().cpu().numpy())\n",
        "                all_dominance_labels.append(dominance_labels.cpu().numpy())\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error in test batch: {e}\")\n",
        "                continue\n",
        "\n",
        "    if num_batches > 0:\n",
        "        test_loss /= num_batches\n",
        "        test_arousal_loss /= num_batches\n",
        "        test_dominance_loss /= num_batches\n",
        "\n",
        "        from scipy.stats import pearsonr\n",
        "        all_arousal_preds = np.concatenate(all_arousal_preds)\n",
        "        all_arousal_labels = np.concatenate(all_arousal_labels)\n",
        "        all_dominance_preds = np.concatenate(all_dominance_preds)\n",
        "        all_dominance_labels = np.concatenate(all_dominance_labels)\n",
        "\n",
        "        arousal_pcc, _ = pearsonr(all_arousal_preds, all_arousal_labels)\n",
        "        dominance_pcc, _ = pearsonr(all_dominance_preds, all_dominance_labels)\n",
        "    else:\n",
        "        test_loss = float('inf')\n",
        "        test_arousal_loss = float('inf')\n",
        "        test_dominance_loss = float('inf')\n",
        "        arousal_pcc = 0.0\n",
        "        dominance_pcc = 0.0\n",
        "\n",
        "    return test_loss, test_arousal_loss, test_dominance_loss, arousal_pcc, dominance_pcc\n",
        "\n",
        "# Main execution\n",
        "def main():\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    # Configuration\n",
        "    csv_file = \"/content/sample_data/updated_iemocap_metadata_colab.csv\"\n",
        "    audio_feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\"facebook/hubert-base-ls960\")\n",
        "    text_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "    hubert_model = HubertModel.from_pretrained(\"facebook/hubert-base-ls960\")\n",
        "    for param in hubert_model.parameters():\n",
        "        param.requires_grad = False\n",
        "    hubert_model.eval()\n",
        "    hubert_model = hubert_model.to(device)\n",
        "\n",
        "    # Dataset and loaders\n",
        "    train_dataset = MultimodalIEMOCAPDataset(\n",
        "        csv_file=csv_file,\n",
        "        audio_feature_extractor=audio_feature_extractor,\n",
        "        text_tokenizer=text_tokenizer,\n",
        "        augment=True,\n",
        "        max_audio_samples=128000\n",
        "    )\n",
        "    val_dataset = MultimodalIEMOCAPDataset(\n",
        "        csv_file=csv_file,\n",
        "        audio_feature_extractor=audio_feature_extractor,\n",
        "        text_tokenizer=text_tokenizer,\n",
        "        augment=False,\n",
        "        max_audio_samples=128000\n",
        "    )\n",
        "    test_dataset = MultimodalIEMOCAPDataset(\n",
        "        csv_file=csv_file,\n",
        "        audio_feature_extractor=audio_feature_extractor,\n",
        "        text_tokenizer=text_tokenizer,\n",
        "        augment=False,\n",
        "        max_audio_samples=128000\n",
        "    )\n",
        "\n",
        "    train_size = int(0.8 * len(train_dataset))\n",
        "    val_size = int(0.1 * len(train_dataset))\n",
        "    test_size = len(train_dataset) - train_size - val_size\n",
        "    train_dataset, _, _ = random_split(\n",
        "        train_dataset, [train_size, val_size, test_size],\n",
        "        generator=torch.Generator().manual_seed(42)\n",
        "    )\n",
        "    _, val_dataset, _ = random_split(\n",
        "        val_dataset, [train_size, val_size, test_size],\n",
        "        generator=torch.Generator().manual_seed(42)\n",
        "    )\n",
        "    _, _, test_dataset = random_split(\n",
        "        test_dataset, [train_size, val_size, test_size],\n",
        "        generator=torch.Generator().manual_seed(42)\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=8,\n",
        "        shuffle=True,\n",
        "        num_workers=0,\n",
        "        pin_memory=True,\n",
        "        collate_fn=dynamic_collate_fn\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=8,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        pin_memory=True,\n",
        "        collate_fn=dynamic_collate_fn\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=8,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        pin_memory=True,\n",
        "        collate_fn=dynamic_collate_fn\n",
        "    )\n",
        "\n",
        "    # Initialize the model\n",
        "    model = MultimodalArousalDominanceModel(\n",
        "        audio_dim=768,\n",
        "        text_dim=768,\n",
        "        hidden_dim=192,\n",
        "        num_heads=6,\n",
        "        num_layers=2,\n",
        "        dropout=0.5\n",
        "    ).to(device)\n",
        "\n",
        "    # Training\n",
        "    print(\"Training Arousal and Dominance model...\")\n",
        "    best_val_loss = train_emotion_model(\n",
        "        model,\n",
        "        train_loader,\n",
        "        val_loader,\n",
        "        hubert_model,\n",
        "        num_epochs=15,\n",
        "        lr=5e-5,\n",
        "        max_norm=1.0\n",
        "    )\n",
        "\n",
        "    # Evaluation\n",
        "    model.load_state_dict(torch.load('/content/best_arousal_dominance_model.pth'))\n",
        "    test_loss, test_arousal_loss, test_dominance_loss, arousal_pcc, dominance_pcc = evaluate_emotion_model(\n",
        "        model, test_loader, hubert_model, device\n",
        "    )\n",
        "\n",
        "    print(\"\\nTest Results:\")\n",
        "    print(f\"  Overall Test Loss: {test_loss:.4f}\")\n",
        "    print(f\"  Arousal MSE: {test_arousal_loss:.4f}, PCC: {arousal_pcc:.4f}\")\n",
        "    print(f\"  Dominance MSE: {test_dominance_loss:.4f}, PCC: {dominance_pcc:.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "40Q7X4YUNySK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41a0bdf9-a604-48eb-b26c-886ef07579d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Arousal and Dominance model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/15 [Train]:   0%|          | 1/1004 [00:00<10:42,  1.56it/s, loss=0.7697, a_loss=0.3017, d_loss=0.4680]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 1.7369\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.7337\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0602\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0610\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 1.8725\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.1073\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 1.5990\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.6528\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0603\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0520\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 1.7725\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.1039\n",
            "shared_fc_arousal.0.weight: Grad Norm = 1.3586\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.1959\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0633\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0611\n",
            "shared_fc_dominance.0.weight: Grad Norm = 1.3562\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.1830\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0766\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0637\n",
            "output_branch_arousal.0.weight: Grad Norm = 1.3682\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0874\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0474\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0455\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.8066\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0139\n",
            "output_branch_dominance.0.weight: Grad Norm = 1.6411\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.1699\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0962\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0939\n",
            "output_branch_dominance.4.weight: Grad Norm = 1.2192\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.2146\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/15 [Train]:  10%|█         | 101/1004 [00:56<08:01,  1.88it/s, loss=0.5750, a_loss=0.1902, d_loss=0.3848]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 1.2496\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.4401\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0436\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0412\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 1.4112\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0748\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 1.7919\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.6621\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0606\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0579\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 1.9217\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.1040\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.9900\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.1323\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0522\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0392\n",
            "shared_fc_dominance.0.weight: Grad Norm = 1.4174\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.1832\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0801\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0604\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.9798\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0626\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0393\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0338\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.6771\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0340\n",
            "output_branch_dominance.0.weight: Grad Norm = 1.3332\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0791\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0557\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0431\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.8322\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0502\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/15 [Train]:  20%|██        | 201/1004 [01:51<07:00,  1.91it/s, loss=0.6419, a_loss=0.2649, d_loss=0.3770]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 1.8727\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.6892\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0682\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0650\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 2.0849\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.1332\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 1.6503\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.5803\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0613\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0551\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 1.6863\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0879\n",
            "shared_fc_arousal.0.weight: Grad Norm = 1.4763\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.2251\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0709\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0658\n",
            "shared_fc_dominance.0.weight: Grad Norm = 1.1860\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.1485\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0570\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0456\n",
            "output_branch_arousal.0.weight: Grad Norm = 1.5115\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.1543\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0753\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0777\n",
            "output_branch_arousal.4.weight: Grad Norm = 1.1493\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.2325\n",
            "output_branch_dominance.0.weight: Grad Norm = 1.1906\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0731\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0454\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0368\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.6828\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0208\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/15 [Train]:  30%|██▉       | 301/1004 [02:47<06:46,  1.73it/s, loss=0.4837, a_loss=0.1158, d_loss=0.3680]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.9406\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.2809\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0334\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0305\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 1.0644\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0515\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 1.4085\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.4642\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0526\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0461\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 1.5657\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0815\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.7740\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0944\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0360\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0310\n",
            "shared_fc_dominance.0.weight: Grad Norm = 1.1188\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.1356\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0498\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0478\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.8339\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0574\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0324\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0309\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.5853\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0587\n",
            "output_branch_dominance.0.weight: Grad Norm = 1.1550\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0767\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0484\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0428\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.7347\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0415\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/15 [Train]:  40%|███▉      | 401/1004 [03:42<05:30,  1.83it/s, loss=0.3776, a_loss=0.1970, d_loss=0.1806]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.9827\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.2859\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0336\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0335\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 1.0304\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0588\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.8897\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.2505\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0357\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0311\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 1.0702\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0596\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.7759\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.1031\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0365\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0333\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.8061\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0982\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0434\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0365\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.8316\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0468\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0304\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0286\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.5239\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0197\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.8834\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0492\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0450\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0314\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.6207\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0110\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/15 [Train]:  50%|████▉     | 501/1004 [04:38<04:50,  1.73it/s, loss=0.4709, a_loss=0.2376, d_loss=0.2333]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 1.0019\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.2920\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0373\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0345\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 1.3378\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0831\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.9114\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.2487\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0346\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0303\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 1.1492\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0546\n",
            "shared_fc_arousal.0.weight: Grad Norm = 1.0382\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.1424\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0551\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0504\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.9348\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0977\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0423\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0431\n",
            "output_branch_arousal.0.weight: Grad Norm = 1.1668\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.1262\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0585\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0631\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.8655\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.1964\n",
            "output_branch_dominance.0.weight: Grad Norm = 1.0349\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0635\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0387\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0349\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.6538\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/15 [Train]:  60%|█████▉    | 601/1004 [05:35<03:46,  1.78it/s, loss=0.2712, a_loss=0.1630, d_loss=0.1082]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.8459\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.2063\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0303\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0282\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.9970\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0488\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.4691\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.1260\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0184\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0160\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.6359\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0342\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.7464\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0849\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0351\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0293\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.5080\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0565\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0328\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0256\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.8023\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0485\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0309\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0275\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.6341\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0046\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.6761\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0519\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0428\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0341\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.4951\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0790\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/15 [Train]:  70%|██████▉   | 701/1004 [06:30<02:44,  1.84it/s, loss=0.4041, a_loss=0.2000, d_loss=0.2040]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 1.1270\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.3469\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0462\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0425\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 1.3907\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0858\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 1.0122\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.3085\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0399\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0370\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 1.1837\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0791\n",
            "shared_fc_arousal.0.weight: Grad Norm = 1.0830\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.1424\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0472\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0550\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.9954\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.1347\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0549\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0559\n",
            "output_branch_arousal.0.weight: Grad Norm = 1.2237\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.1566\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0569\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0704\n",
            "output_branch_arousal.4.weight: Grad Norm = 1.0631\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.2168\n",
            "output_branch_dominance.0.weight: Grad Norm = 1.3236\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.1375\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0706\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0845\n",
            "output_branch_dominance.4.weight: Grad Norm = 1.3884\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.2732\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/15 [Train]:  80%|███████▉  | 801/1004 [07:26<01:48,  1.88it/s, loss=0.4453, a_loss=0.1864, d_loss=0.2589]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.8670\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.2299\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0336\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0299\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.9297\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0564\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.6259\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.1581\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0273\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0224\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.7651\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0378\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.7399\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0961\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0426\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0355\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.6065\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0682\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0393\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0281\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.9557\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0823\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0461\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0491\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.8890\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.1619\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.7069\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0370\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0285\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0273\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.6193\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0646\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/15 [Train]:  90%|████████▉ | 901/1004 [08:23<00:55,  1.86it/s, loss=0.4665, a_loss=0.2380, d_loss=0.2285]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.8576\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.2205\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0362\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0294\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 1.0463\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0575\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.5904\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.1507\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0263\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0214\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.8024\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0408\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.8188\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0982\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0406\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0373\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.6192\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0637\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0325\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0297\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.8875\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0525\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0376\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0312\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.7248\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0127\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.7894\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0456\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0305\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0314\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.5175\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0343\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/15 [Train]: 100%|█████████▉| 1001/1004 [09:17<00:01,  1.97it/s, loss=0.3570, a_loss=0.1981, d_loss=0.1588]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.8663\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.1892\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0355\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0314\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 1.1058\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0638\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.4606\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0924\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0207\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0169\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.5999\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0302\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.8540\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.1040\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0418\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0436\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.4576\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0521\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0290\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0226\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.9462\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.1052\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0498\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0557\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.9642\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.1970\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.6791\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0451\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0346\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0338\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.5977\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/15 [Train]: 100%|██████████| 1004/1004 [09:19<00:00,  1.79it/s, loss=0.3073, a_loss=0.1535, d_loss=0.1538]\n",
            "Epoch 1/15 [Val]:   0%|          | 0/126 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:544: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)\n",
            "  return torch._transformer_encoder_layer_fwd(\n",
            "Epoch 1/15 [Val]: 100%|██████████| 126/126 [00:45<00:00,  2.75it/s, loss=0.3696, a_loss=0.2295, d_loss=0.5096]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15 Results:\n",
            "  Train Loss: 0.5051 (Arousal: 0.2214, Dominance: 0.2837)\n",
            "  Val Loss: 0.1893 (Arousal: 0.1610, Dominance: 0.2176)\n",
            "  Loss Weights - Arousal: 0.2500, Dominance: 0.7500\n",
            "  Saved best model (val_loss: 0.1893)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/15 [Train]:   0%|          | 1/1004 [00:00<11:36,  1.44it/s, loss=0.2484, a_loss=0.3076, d_loss=0.2287]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.2406\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0571\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0097\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0086\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.2845\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0167\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.4924\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.1173\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0227\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0189\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.6278\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0321\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.2075\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0252\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0095\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0098\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.4778\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0538\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0273\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0245\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.2549\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0186\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0097\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0109\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1946\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0328\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.6486\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0518\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0298\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0293\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.5446\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0824\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/15 [Train]:  10%|█         | 101/1004 [00:56<08:24,  1.79it/s, loss=0.2441, a_loss=0.2177, d_loss=0.2530]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.1926\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0393\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0071\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0068\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.2253\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0128\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.4792\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.1158\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0225\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0183\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.6068\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0282\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.1739\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0212\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0089\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0084\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.5048\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0521\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0267\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0244\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.2244\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0150\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0077\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0082\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1560\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0038\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.6425\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0496\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0292\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0276\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.5083\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0362\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/15 [Train]:  20%|██        | 201/1004 [01:51<07:18,  1.83it/s, loss=0.1395, a_loss=0.0856, d_loss=0.1574]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.1559\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0427\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0062\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0058\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.1628\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0104\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.5399\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.1462\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0226\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0202\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.6511\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0350\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.1226\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0167\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0062\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0065\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.4982\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0616\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0236\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0252\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1839\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0183\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0100\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0109\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1926\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0392\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.5502\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0432\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0316\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0306\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.5233\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0715\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/15 [Train]:  30%|██▉       | 301/1004 [02:45<05:51,  2.00it/s, loss=0.1545, a_loss=0.2809, d_loss=0.1124]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.1596\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0420\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0064\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0056\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.2026\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0114\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.2767\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0779\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0137\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0110\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.3800\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0190\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.1557\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0194\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0077\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0076\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.3467\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0336\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0204\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0191\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1900\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0139\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0099\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0092\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1729\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0199\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.4834\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0443\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0244\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0307\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.6018\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0939\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/15 [Train]:  40%|███▉      | 401/1004 [03:40<05:20,  1.88it/s, loss=0.1935, a_loss=0.1613, d_loss=0.2043]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.1637\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0409\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0070\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0057\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.1879\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0105\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.3213\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0816\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0148\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0126\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.4482\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0213\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.1545\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0206\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0086\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0079\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.3308\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0349\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0174\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0165\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1940\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0152\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0078\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0084\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1742\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0200\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.4199\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0227\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0166\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0165\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.3428\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0118\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/15 [Train]:  50%|████▉     | 501/1004 [04:35<04:18,  1.95it/s, loss=0.2337, a_loss=0.0943, d_loss=0.2801]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.1428\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0420\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0048\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0049\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.1599\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0085\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.3319\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0889\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0170\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0128\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.4505\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0224\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.1336\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0157\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0066\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0064\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.3853\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0378\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0224\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0195\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1582\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0106\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0060\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0054\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1145\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0053\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.6353\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0535\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0368\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0405\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.6459\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.1130\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/15 [Train]:  60%|█████▉    | 601/1004 [05:29<03:34,  1.88it/s, loss=0.3600, a_loss=0.1785, d_loss=0.4205]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.1360\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0330\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0061\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0048\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.1631\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0087\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.3692\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0971\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0191\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0146\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.5342\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0259\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.1312\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0163\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0075\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0065\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.5101\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0480\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0308\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0281\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1765\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0129\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0101\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0096\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1963\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0295\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.7811\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0554\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0328\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0415\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.7702\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0768\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/15 [Train]:  70%|██████▉   | 701/1004 [06:25<02:45,  1.83it/s, loss=0.1873, a_loss=0.1609, d_loss=0.1961]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.1467\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0378\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0064\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0054\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.1774\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0108\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.3876\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.1097\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0226\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0152\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.5155\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0267\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.1497\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0194\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0082\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0079\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.4070\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0430\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0193\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0212\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1988\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0155\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0099\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0103\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1906\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0363\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.5148\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0506\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0290\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0295\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.5120\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/15 [Train]:  80%|███████▉  | 801/1004 [07:19<01:52,  1.81it/s, loss=0.1172, a_loss=0.2786, d_loss=0.0634]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.1741\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0335\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0076\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0058\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.2214\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0105\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1657\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0358\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0089\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0064\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.2175\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0098\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.1830\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0202\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0096\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0089\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1804\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0157\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0108\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0094\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.2788\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0220\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0118\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0129\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1969\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0309\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2239\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0179\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0126\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0118\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.2370\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0253\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/15 [Train]:  90%|████████▉ | 901/1004 [08:13<00:53,  1.92it/s, loss=0.1846, a_loss=0.1307, d_loss=0.2026]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.1509\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0299\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0056\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0052\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.1770\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0094\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.2631\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0618\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0127\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0107\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.3778\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0208\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.1381\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0179\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0071\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0067\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.3438\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0357\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0232\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0199\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1516\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0106\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0059\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0062\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1381\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0043\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.6569\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0609\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0393\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0498\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.8192\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.1686\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/15 [Train]: 100%|█████████▉| 1001/1004 [09:08<00:01,  1.86it/s, loss=0.1843, a_loss=0.1111, d_loss=0.2086]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.1662\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0486\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0071\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0064\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.1971\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0123\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.3394\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0958\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0169\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0137\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.4451\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0254\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.1492\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0200\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0072\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0077\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.3891\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0416\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0241\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0232\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.2001\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0225\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0104\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0115\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.2109\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0434\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.6424\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0512\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0370\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0452\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.7062\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.1285\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/15 [Train]: 100%|██████████| 1004/1004 [09:09<00:00,  1.83it/s, loss=0.1755, a_loss=0.1477, d_loss=0.1848]\n",
            "Epoch 2/15 [Val]: 100%|██████████| 126/126 [00:44<00:00,  2.82it/s, loss=0.2787, a_loss=0.2486, d_loss=0.3087]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/15 Results:\n",
            "  Train Loss: 0.2093 (Arousal: 0.1664, Dominance: 0.2236)\n",
            "  Val Loss: 0.1594 (Arousal: 0.1294, Dominance: 0.1895)\n",
            "  Loss Weights - Arousal: 0.2500, Dominance: 0.7500\n",
            "  Saved best model (val_loss: 0.1594)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/15 [Train]:   0%|          | 1/1004 [00:00<09:05,  1.84it/s, loss=0.2278, a_loss=0.0716, d_loss=0.2799]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0956\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0232\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0033\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0035\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.1196\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0073\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.3256\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0771\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0161\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0129\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.5042\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0238\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0952\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0121\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0055\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0049\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.4144\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0389\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0229\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0238\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1535\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0125\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0065\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0077\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1342\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0237\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.5585\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0380\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0282\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0261\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.5062\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/15 [Train]:  10%|█         | 101/1004 [00:55<07:11,  2.09it/s, loss=0.2027, a_loss=0.3010, d_loss=0.1699]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.1441\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0319\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0055\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0050\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.2090\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0109\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.2972\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0712\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0150\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0113\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.4277\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0198\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.1622\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0185\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0090\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0082\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.3625\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0339\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0207\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0187\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.2179\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0198\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0127\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0127\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.2879\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0423\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.4926\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0302\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0238\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0250\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.4623\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0497\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/15 [Train]:  20%|██        | 201/1004 [01:51<06:36,  2.02it/s, loss=0.1526, a_loss=0.1708, d_loss=0.1465]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.1453\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0272\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0062\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0050\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.1521\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0077\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.2580\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0569\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0125\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0105\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.3702\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0182\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.1225\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0134\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0072\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0058\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.3158\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0310\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0204\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0176\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1703\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0096\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0068\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0064\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1424\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0012\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.4658\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0360\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0199\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0233\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.4104\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0542\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/15 [Train]:  30%|██▉       | 301/1004 [02:46<06:32,  1.79it/s, loss=0.1488, a_loss=0.0352, d_loss=0.1867]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0663\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0143\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0028\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0024\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0725\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0041\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.2755\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0623\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0139\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0118\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.4007\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0218\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0588\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0067\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0029\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0029\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.3522\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0335\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0235\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0209\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0900\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0077\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0048\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0054\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1180\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0190\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.6082\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0563\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0313\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0419\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.7577\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.1276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/15 [Train]:  40%|███▉      | 401/1004 [03:40<06:02,  1.66it/s, loss=0.2226, a_loss=0.1722, d_loss=0.2393]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.1123\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0310\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0042\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0040\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.1355\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0073\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.2696\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0714\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0146\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0115\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.3767\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0188\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.1059\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0119\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0055\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0053\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.3079\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0311\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0186\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0165\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1541\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0117\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0063\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0071\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1149\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0159\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.4165\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0249\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0157\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0167\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.3987\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0343\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/15 [Train]:  50%|████▉     | 501/1004 [04:33<05:03,  1.66it/s, loss=0.1525, a_loss=0.0832, d_loss=0.1756]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0811\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0219\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0034\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0029\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.1036\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0051\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.2050\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0353\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0113\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0090\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.3131\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0141\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0823\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0087\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0042\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0041\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.2727\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0248\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0155\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0151\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1160\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0064\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0043\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0037\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.0821\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0038\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.3988\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0262\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0167\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0219\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.4436\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/15 [Train]:  60%|█████▉    | 601/1004 [05:29<04:09,  1.62it/s, loss=0.2961, a_loss=0.1345, d_loss=0.3500]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.1169\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0297\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0046\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0041\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.1291\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0071\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.2253\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0576\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0107\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0095\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.3470\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0169\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.1037\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0125\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0049\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0050\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.3223\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0291\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0222\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0195\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1608\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0114\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0060\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0072\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1834\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0247\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.5736\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0424\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0374\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0355\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.6360\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0791\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/15 [Train]:  70%|██████▉   | 701/1004 [06:25<02:41,  1.87it/s, loss=0.2472, a_loss=0.2428, d_loss=0.2487]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.1566\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0342\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0060\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0056\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.1832\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0093\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.2086\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0496\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0111\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0089\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.3116\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0138\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.1528\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0166\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0077\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0079\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.2755\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0247\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0185\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0156\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.2034\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0151\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0083\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0087\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1674\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0101\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.4139\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0271\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0199\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0228\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.4249\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0530\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/15 [Train]:  80%|███████▉  | 801/1004 [07:18<01:56,  1.75it/s, loss=0.0717, a_loss=0.0386, d_loss=0.0828]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0471\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0103\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0017\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0017\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0595\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0028\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1366\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0299\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0069\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0062\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1932\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0098\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0483\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0046\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0033\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0025\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1676\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0157\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0098\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0100\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0727\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0046\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0026\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0031\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.0680\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0061\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.3174\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0290\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0181\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0241\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.5626\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0810\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/15 [Train]:  90%|████████▉ | 901/1004 [08:13<00:59,  1.75it/s, loss=0.1788, a_loss=0.2013, d_loss=0.1713]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.1316\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0246\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0051\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0046\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.1524\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0093\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.2094\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0492\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0121\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0094\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.2592\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0150\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.1165\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0143\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0064\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0060\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.2193\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0229\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0135\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0128\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1969\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0175\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0077\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0116\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.2524\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0410\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.3684\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0268\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0193\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0221\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.5768\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0584\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/15 [Train]: 100%|█████████▉| 1001/1004 [09:08<00:01,  1.92it/s, loss=0.1944, a_loss=0.2009, d_loss=0.1922]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.1267\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0327\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0054\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0049\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.1570\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0094\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.2967\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0836\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0164\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0128\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.3590\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0186\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.1247\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0156\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0080\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0072\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.3231\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0317\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0161\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0181\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1763\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0175\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0120\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0118\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.2238\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0391\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.4019\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0274\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0231\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0215\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.4007\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/15 [Train]: 100%|██████████| 1004/1004 [09:09<00:00,  1.83it/s, loss=0.1696, a_loss=0.0682, d_loss=0.2034]\n",
            "Epoch 3/15 [Val]: 100%|██████████| 126/126 [00:44<00:00,  2.81it/s, loss=0.3748, a_loss=0.2896, d_loss=0.4600]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/15 Results:\n",
            "  Train Loss: 0.1974 (Arousal: 0.1564, Dominance: 0.2110)\n",
            "  Val Loss: 0.1586 (Arousal: 0.1281, Dominance: 0.1891)\n",
            "  Loss Weights - Arousal: 0.2500, Dominance: 0.7500\n",
            "  Saved best model (val_loss: 0.1586)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/15 [Train]:   0%|          | 1/1004 [00:00<11:42,  1.43it/s, loss=0.2031, a_loss=0.0894, d_loss=0.2410]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0948\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0222\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0040\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0035\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.1168\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0065\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.2511\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0616\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0130\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0114\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.3134\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0188\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0929\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0111\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0062\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0050\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.2687\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0282\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0188\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0168\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1359\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0089\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0060\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0060\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1286\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0168\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.5795\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0478\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0308\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0464\n",
            "output_branch_dominance.4.weight: Grad Norm = 1.0082\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.1562\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/15 [Train]:  10%|█         | 101/1004 [00:54<09:22,  1.60it/s, loss=0.2306, a_loss=0.0751, d_loss=0.2824]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0984\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0180\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0043\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0036\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.1148\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0066\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.2417\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0476\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0113\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0097\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.3156\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0161\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0904\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0116\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0056\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0047\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.2861\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0271\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0166\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0159\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1225\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0127\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0072\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0083\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1739\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0350\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.4153\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0266\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0191\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0240\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.4573\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0645\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/15 [Train]:  20%|██        | 201/1004 [01:49<08:10,  1.64it/s, loss=0.2142, a_loss=0.0501, d_loss=0.2689]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0739\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0164\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0031\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0026\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0798\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0041\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.3034\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0783\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0159\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0140\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.3671\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0247\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0624\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0069\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0033\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0030\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.3286\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0389\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0242\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0208\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0932\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0068\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0037\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0045\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1012\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0111\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.4985\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0415\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0285\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0405\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.7465\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.1164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/15 [Train]:  30%|██▉       | 301/1004 [02:44<07:30,  1.56it/s, loss=0.1598, a_loss=0.1785, d_loss=0.1535]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.1608\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0451\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0060\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0060\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.1967\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0135\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1835\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0413\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0104\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0080\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.2727\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0134\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.1425\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0187\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0086\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0078\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.2504\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0238\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0172\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0147\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.2215\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0229\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0127\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0160\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.3480\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0599\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.3552\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0266\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0165\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0190\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.3475\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0216\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/15 [Train]:  40%|███▉      | 401/1004 [03:39<05:30,  1.83it/s, loss=0.1655, a_loss=0.1320, d_loss=0.1766]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.1155\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0297\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0051\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0043\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.1379\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0073\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.2175\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0462\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0119\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0093\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.3146\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0146\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.1127\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0121\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0058\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0059\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.2822\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0264\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0160\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0165\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1413\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0103\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0060\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0059\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1289\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0084\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.4047\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0248\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0194\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0220\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.4827\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/15 [Train]:  50%|████▉     | 501/1004 [04:35<05:00,  1.68it/s, loss=0.2485, a_loss=0.1303, d_loss=0.2878]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.1353\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0382\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0063\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0051\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.1522\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0083\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.2580\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0694\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0137\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0112\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.3337\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0163\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.1213\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0145\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0079\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0064\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.2988\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0287\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0189\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0173\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1634\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0128\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0081\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0079\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1438\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0112\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.3955\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0237\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0195\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0189\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.4256\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/15 [Train]:  60%|█████▉    | 601/1004 [05:29<03:41,  1.82it/s, loss=0.1089, a_loss=0.1527, d_loss=0.0943]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.1098\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0259\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0045\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0039\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.1390\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0071\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1636\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0439\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0096\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0074\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.2144\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0114\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.1098\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0124\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0059\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0057\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.2026\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0180\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0129\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0127\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1766\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0146\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0067\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0095\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.2048\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0264\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.3372\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0307\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0212\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0230\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.4766\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/15 [Train]:  70%|██████▉   | 701/1004 [06:23<02:39,  1.90it/s, loss=0.2665, a_loss=0.0792, d_loss=0.3290]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0860\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0215\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0042\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0031\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.1078\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0057\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.2442\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0545\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0128\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0103\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.3408\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0147\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0837\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0094\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0053\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0043\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.2768\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0242\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0158\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0152\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1148\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0081\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0069\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0056\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1022\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0085\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.4204\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0225\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0174\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0184\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.3462\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/15 [Train]:  80%|███████▉  | 801/1004 [07:18<01:55,  1.76it/s, loss=0.0777, a_loss=0.0733, d_loss=0.0791]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0803\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0192\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0034\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0029\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0976\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0048\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1276\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0323\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0078\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0056\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1747\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0083\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0812\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0086\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0047\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0040\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1558\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0128\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0092\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0089\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1044\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0075\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0046\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0047\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1064\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0123\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2902\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0204\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0165\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0183\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.3380\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0452\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/15 [Train]:  90%|████████▉ | 901/1004 [08:13<00:57,  1.80it/s, loss=0.1689, a_loss=0.1159, d_loss=0.1866]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0989\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0224\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0041\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0035\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.1220\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0062\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1472\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0283\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0084\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0065\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.2306\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0104\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.1002\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0104\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0057\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0050\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1988\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0189\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0117\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0111\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1270\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0093\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0058\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0062\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1259\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0175\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.3257\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0203\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0143\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0170\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.3194\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0114\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/15 [Train]: 100%|█████████▉| 1001/1004 [09:07<00:01,  1.84it/s, loss=0.0990, a_loss=0.0668, d_loss=0.1097]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0877\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0130\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0037\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0032\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0963\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0057\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.2074\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0347\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0103\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0095\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.2563\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0152\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0790\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0086\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0051\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0043\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.2234\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0236\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0146\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0139\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1217\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0115\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0066\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0081\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1661\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0306\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.3863\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0301\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0222\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0290\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.5476\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0872\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/15 [Train]: 100%|██████████| 1004/1004 [09:09<00:00,  1.83it/s, loss=0.2937, a_loss=0.0904, d_loss=0.3615]\n",
            "Epoch 4/15 [Val]: 100%|██████████| 126/126 [00:44<00:00,  2.81it/s, loss=0.4390, a_loss=0.3600, d_loss=0.5180]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/15 Results:\n",
            "  Train Loss: 0.1842 (Arousal: 0.1485, Dominance: 0.1961)\n",
            "  Val Loss: 0.1729 (Arousal: 0.1413, Dominance: 0.2045)\n",
            "  Loss Weights - Arousal: 0.2500, Dominance: 0.7500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/15 [Train]:   0%|          | 1/1004 [00:00<08:34,  1.95it/s, loss=0.2605, a_loss=0.0652, d_loss=0.3256]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0635\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0149\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0026\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0023\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0720\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0041\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.2378\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0542\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0131\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0113\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.2841\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0152\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0623\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0070\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0035\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0034\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.2454\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0264\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0153\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0143\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1059\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0091\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0049\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0064\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1395\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0253\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.3538\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0232\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0170\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0186\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.3755\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0045\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/15 [Train]:  10%|█         | 101/1004 [00:55<08:00,  1.88it/s, loss=0.2570, a_loss=0.2067, d_loss=0.2737]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.1173\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0248\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0053\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0044\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.1478\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0081\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.2660\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0581\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0152\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0128\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.3172\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0193\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.1186\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0139\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0066\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0063\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.2747\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0284\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0147\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0171\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1534\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0099\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0066\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0070\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1349\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0043\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.4376\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0359\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0210\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0275\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.7045\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/15 [Train]:  20%|██        | 201/1004 [01:49<08:02,  1.67it/s, loss=0.2247, a_loss=0.3705, d_loss=0.1761]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.1388\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0255\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0057\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0047\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.1561\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0078\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1832\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0355\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0090\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0079\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.2608\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0124\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.1293\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0132\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0067\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0061\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.2358\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0213\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0153\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0141\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1829\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0136\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0098\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0102\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.2207\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0411\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.3753\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0257\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0169\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0228\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.3857\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0483\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/15 [Train]:  30%|██▉       | 301/1004 [02:44<06:15,  1.87it/s, loss=0.1506, a_loss=0.0398, d_loss=0.1875]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0590\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0108\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0024\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0021\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0644\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0038\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.2125\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0386\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0112\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0093\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.2598\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0136\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0512\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0057\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0025\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0027\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.2211\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0238\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0126\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0129\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0846\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0072\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0036\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0053\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1127\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0197\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.3383\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0187\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0156\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0163\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.4207\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0287\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/15 [Train]:  40%|███▉      | 401/1004 [03:40<06:24,  1.57it/s, loss=0.3145, a_loss=0.1712, d_loss=0.3623]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.1350\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0290\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0056\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0049\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.1614\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0080\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.2401\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0516\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0128\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0110\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.3108\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0156\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.1331\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0146\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0072\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0068\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.2814\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0254\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0191\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0177\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1639\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0102\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0061\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0055\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1259\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0104\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.4907\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0357\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0293\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0378\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.8625\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.1384\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/15 [Train]:  50%|████▉     | 501/1004 [04:34<05:05,  1.65it/s, loss=0.2067, a_loss=0.1326, d_loss=0.2314]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.1270\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0288\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0053\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0046\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.1245\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0079\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1845\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0348\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0104\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0087\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.2655\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0140\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.1051\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0127\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0067\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0058\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.2332\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0226\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0165\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0150\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1406\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0128\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0063\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0084\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.2379\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0380\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.4160\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0317\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0194\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0292\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.5781\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0720\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/15 [Train]:  60%|█████▉    | 601/1004 [05:28<04:00,  1.67it/s, loss=0.1360, a_loss=0.0224, d_loss=0.1739]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0543\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0140\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0024\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0020\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0603\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0036\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1802\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0460\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0100\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0086\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.2597\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0151\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0512\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0057\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0030\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0027\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.2375\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0236\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0151\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0161\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0680\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0053\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0034\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0038\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.0695\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0092\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.4370\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0399\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0235\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0360\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.7770\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.1293\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/15 [Train]:  70%|██████▉   | 701/1004 [06:24<02:49,  1.79it/s, loss=0.1601, a_loss=0.0512, d_loss=0.1965]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0603\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0135\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0023\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0022\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0758\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0046\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1876\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0388\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0101\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0082\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.2576\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0132\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0610\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0073\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0040\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0034\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.2231\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0207\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0136\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0139\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0822\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0062\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0038\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0044\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1022\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0177\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.4033\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0290\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0216\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0260\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.5552\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0661\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/15 [Train]:  80%|███████▉  | 801/1004 [07:19<01:51,  1.82it/s, loss=0.1294, a_loss=0.1366, d_loss=0.1270]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.1160\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0246\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0048\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0044\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.1187\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0065\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1452\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0317\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0082\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0069\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1966\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0099\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.1028\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0122\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0071\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0056\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1688\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0155\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0107\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0103\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1247\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0080\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0063\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0058\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1226\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0022\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2737\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0156\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0129\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0151\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.3806\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/15 [Train]:  90%|████████▉ | 901/1004 [08:13<00:52,  1.95it/s, loss=0.1433, a_loss=0.0525, d_loss=0.1736]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0514\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0112\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0023\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0019\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0592\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0032\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1414\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0331\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0092\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0064\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1917\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0074\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0508\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0054\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0026\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0027\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1677\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0135\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0104\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0098\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0682\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0047\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0030\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0032\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.0756\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0028\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2823\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0185\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0131\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0156\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.3455\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0051\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/15 [Train]: 100%|█████████▉| 1001/1004 [09:08<00:01,  1.94it/s, loss=0.1598, a_loss=0.0852, d_loss=0.1846]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0794\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0180\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0030\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0029\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0870\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0050\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.2141\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0466\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0121\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0099\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.2505\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0126\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0694\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0073\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0046\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0037\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.2143\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0192\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0123\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0133\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1092\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0074\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0047\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0061\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1394\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0150\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.4011\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0340\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0192\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0359\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.6116\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.1181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/15 [Train]: 100%|██████████| 1004/1004 [09:09<00:00,  1.83it/s, loss=0.2476, a_loss=0.1780, d_loss=0.2708]\n",
            "Epoch 5/15 [Val]: 100%|██████████| 126/126 [00:44<00:00,  2.81it/s, loss=0.2817, a_loss=0.2688, d_loss=0.2946]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/15 Results:\n",
            "  Train Loss: 0.1815 (Arousal: 0.1436, Dominance: 0.1941)\n",
            "  Val Loss: 0.1504 (Arousal: 0.1204, Dominance: 0.1804)\n",
            "  Loss Weights - Arousal: 0.2500, Dominance: 0.7500\n",
            "  Saved best model (val_loss: 0.1504)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/15 [Train]:   0%|          | 1/1004 [00:00<10:10,  1.64it/s, loss=0.1683, a_loss=0.2026, d_loss=0.1569]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.1055\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0197\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0045\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0037\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.1248\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0069\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1510\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0310\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0086\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0065\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1941\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0092\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.1030\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0112\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0056\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0052\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1820\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0166\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0122\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0114\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1267\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0109\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0057\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0064\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1679\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0240\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2633\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0133\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0118\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0127\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.3173\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0270\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/15 [Train]:  10%|█         | 101/1004 [00:54<08:42,  1.73it/s, loss=0.0962, a_loss=0.0797, d_loss=0.1016]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0974\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0208\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0036\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0034\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.1021\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0058\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1184\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0236\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0071\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0053\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1680\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0074\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0786\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0093\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0040\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0042\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1415\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0128\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0101\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0087\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0892\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0067\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0039\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0039\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.0977\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0015\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2226\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0126\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0099\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0118\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.2625\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0086\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/15 [Train]:  20%|██        | 201/1004 [01:49<07:59,  1.68it/s, loss=0.1311, a_loss=0.2150, d_loss=0.1031]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0988\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0167\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0042\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0035\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0985\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0053\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1194\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0247\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0055\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0052\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1405\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0066\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0884\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0101\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0056\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0047\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1179\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0110\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0074\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0071\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1198\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0079\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0042\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0053\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1103\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0078\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2151\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0124\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0086\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0113\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.2224\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/15 [Train]:  30%|██▉       | 301/1004 [02:45<07:15,  1.61it/s, loss=0.0955, a_loss=0.1013, d_loss=0.0936]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0913\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0252\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0042\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0032\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.1064\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0047\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1616\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0378\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0088\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0079\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1774\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0126\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0857\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0087\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0045\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0045\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1498\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0177\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0101\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0103\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1016\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0070\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0033\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0040\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1118\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0037\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.3284\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0273\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0155\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0301\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.8175\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.1174\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/15 [Train]:  40%|███▉      | 401/1004 [03:39<05:29,  1.83it/s, loss=0.1037, a_loss=0.0833, d_loss=0.1105]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0758\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0153\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0029\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0028\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0942\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0054\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1520\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0288\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0091\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0072\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1919\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0116\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0779\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0081\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0045\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0042\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1659\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0174\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0113\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0112\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1130\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0098\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0055\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0070\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1809\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0286\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.3001\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0232\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0120\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0213\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.3769\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0748\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/15 [Train]:  50%|████▉     | 501/1004 [04:34<05:05,  1.65it/s, loss=0.2223, a_loss=0.1593, d_loss=0.2433]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.1086\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0286\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0043\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0040\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.1207\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0066\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.2389\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0490\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0133\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0109\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.2840\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0143\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0943\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0112\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0054\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0052\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.2266\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0218\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0139\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0136\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1159\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0091\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0059\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0062\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1241\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0055\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.3711\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0211\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0152\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0198\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.4859\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/15 [Train]:  60%|█████▉    | 601/1004 [05:30<03:43,  1.80it/s, loss=0.2118, a_loss=0.3446, d_loss=0.1675]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.1465\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0341\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0060\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0054\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.1550\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0079\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1261\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0282\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0067\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0060\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1599\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0090\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.1254\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0136\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0079\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0064\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1403\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0130\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0080\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0096\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1701\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0112\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0067\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0079\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1925\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0203\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2653\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0219\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0114\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0221\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.5495\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0916\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/15 [Train]:  70%|██████▉   | 701/1004 [06:25<02:43,  1.85it/s, loss=0.3446, a_loss=0.1435, d_loss=0.4116]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0790\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0179\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0033\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0028\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0966\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0048\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1208\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0301\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0072\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0058\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1791\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0086\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0844\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0088\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0052\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0044\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1730\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0151\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0129\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0111\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1073\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0079\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0040\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0055\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1317\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0164\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2783\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0188\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0135\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0190\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.3690\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0527\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/15 [Train]:  80%|███████▉  | 801/1004 [07:19<01:42,  1.98it/s, loss=0.2434, a_loss=0.2012, d_loss=0.2574]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0897\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0190\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0039\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0033\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.1028\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0057\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1892\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0440\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0105\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0092\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.2348\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0119\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0884\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0097\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0059\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0049\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.2048\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0187\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0146\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0127\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1382\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0081\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0065\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0055\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1280\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0006\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.3724\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0232\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0133\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0205\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.4517\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0017\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/15 [Train]:  90%|████████▉ | 901/1004 [08:14<00:53,  1.93it/s, loss=0.2546, a_loss=0.1061, d_loss=0.3041]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0823\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0183\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0035\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0030\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0956\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0049\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.2100\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0466\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0110\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0096\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.2607\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0122\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0794\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0085\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0045\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0043\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.2317\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0207\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0153\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0142\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1016\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0074\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0042\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0048\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1226\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0144\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.3910\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0309\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0198\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0243\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.6296\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0550\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/15 [Train]: 100%|█████████▉| 1001/1004 [09:08<00:01,  2.01it/s, loss=0.0543, a_loss=0.1471, d_loss=0.0234]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0956\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0213\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0034\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0034\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.1130\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0067\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.0719\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0177\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0040\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0035\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.0885\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0042\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0891\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0099\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0047\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0049\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.0783\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0066\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0054\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0047\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1410\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0136\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0076\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0100\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.2682\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0485\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.1130\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0069\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0060\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0055\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.1348\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0039\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/15 [Train]: 100%|██████████| 1004/1004 [09:10<00:00,  1.82it/s, loss=0.1644, a_loss=0.1186, d_loss=0.1797]\n",
            "Epoch 6/15 [Val]: 100%|██████████| 126/126 [00:44<00:00,  2.80it/s, loss=0.3242, a_loss=0.2792, d_loss=0.3692]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/15 Results:\n",
            "  Train Loss: 0.1701 (Arousal: 0.1343, Dominance: 0.1821)\n",
            "  Val Loss: 0.1501 (Arousal: 0.1198, Dominance: 0.1804)\n",
            "  Loss Weights - Arousal: 0.2500, Dominance: 0.7500\n",
            "  Saved best model (val_loss: 0.1501)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/15 [Train]:   0%|          | 1/1004 [00:00<09:45,  1.71it/s, loss=0.0776, a_loss=0.0823, d_loss=0.0761]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0849\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0168\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0032\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0031\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0971\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0058\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.0910\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0187\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0045\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0042\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1319\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0069\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0819\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0093\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0054\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0048\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1199\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0112\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0087\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0077\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0972\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0089\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0047\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0061\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1671\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0257\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2066\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0124\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0089\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0137\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.3694\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0454\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/15 [Train]:  10%|█         | 101/1004 [00:55<08:39,  1.74it/s, loss=0.1010, a_loss=0.1491, d_loss=0.0850]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.1145\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0311\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0049\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0044\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.1313\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0078\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1089\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0223\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0052\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0047\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1384\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0068\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.1036\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0123\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0067\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0059\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1196\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0114\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0081\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0077\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1412\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0093\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0061\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0068\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1464\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0011\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2070\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0110\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0107\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0112\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.2949\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/15 [Train]:  20%|██        | 201/1004 [01:50<07:14,  1.85it/s, loss=0.1679, a_loss=0.1274, d_loss=0.1814]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.1026\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0198\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0037\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0035\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.1051\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0052\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.2145\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0561\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0114\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0098\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.2664\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0135\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0828\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0091\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0044\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0042\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.2289\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0218\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0150\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0150\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1046\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0084\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0058\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0057\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1490\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0239\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.3266\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0289\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0215\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0240\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.3855\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/15 [Train]:  30%|██▉       | 301/1004 [02:44<05:45,  2.04it/s, loss=0.0825, a_loss=0.0809, d_loss=0.0830]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0557\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0135\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0023\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0021\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0625\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0035\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1557\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0391\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0089\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0077\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1775\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0111\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0495\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0056\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0030\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0027\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1596\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0156\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0106\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0113\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0885\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0066\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0043\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0054\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1594\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0230\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2641\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0240\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0128\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0243\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.5887\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/15 [Train]:  40%|███▉      | 401/1004 [03:40<05:31,  1.82it/s, loss=0.1311, a_loss=0.0801, d_loss=0.1481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0835\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0170\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0035\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0029\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0920\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0048\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.2498\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0735\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0142\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0126\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.2971\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0176\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0743\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0081\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0038\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0038\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.2574\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0266\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0162\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0173\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0997\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0078\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0049\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0056\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1339\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0193\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.3548\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0373\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0166\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0313\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.8287\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.1307\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/15 [Train]:  50%|████▉     | 501/1004 [04:36<04:28,  1.87it/s, loss=0.1907, a_loss=0.0844, d_loss=0.2261]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0712\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0168\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0030\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0026\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0813\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0045\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.2343\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0584\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0119\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0107\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.2929\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0159\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0687\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0079\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0034\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0037\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.2566\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0253\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0166\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0161\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0958\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0070\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0051\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0053\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1476\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0218\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.3739\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0296\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0206\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0253\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.3999\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0638\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/15 [Train]:  60%|█████▉    | 601/1004 [05:31<03:34,  1.87it/s, loss=0.2368, a_loss=0.0944, d_loss=0.2843]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0759\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0200\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0028\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0029\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0846\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0048\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.2177\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0494\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0109\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0099\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.2839\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0158\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0687\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0077\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0043\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0040\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.2549\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0255\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0167\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0168\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1038\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0086\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0050\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0067\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1527\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0279\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.3728\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0241\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0215\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0222\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.4367\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/15 [Train]:  70%|██████▉   | 701/1004 [06:26<02:45,  1.83it/s, loss=0.1779, a_loss=0.1439, d_loss=0.1893]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.1438\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0345\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0057\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0054\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.1632\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0104\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1291\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0258\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0058\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0055\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1652\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0081\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.1243\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0157\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0063\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0073\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1515\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0131\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0097\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0099\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1569\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0160\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0088\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0100\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.2794\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0422\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2555\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0174\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0116\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0168\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.3522\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0294\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/15 [Train]:  80%|███████▉  | 801/1004 [07:22<01:49,  1.86it/s, loss=0.1640, a_loss=0.2367, d_loss=0.1398]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0810\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0193\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0036\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0030\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.1048\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0053\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.2351\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0589\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0136\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0108\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.2740\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0164\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0925\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0101\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0051\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0052\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.2317\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0228\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0155\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0156\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1381\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0077\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0053\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0057\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1684\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0093\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.3759\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0362\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0203\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0350\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.9285\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.1322\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/15 [Train]:  90%|████████▉ | 901/1004 [08:16<01:00,  1.71it/s, loss=0.2370, a_loss=0.1239, d_loss=0.2746]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0805\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0208\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0035\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0031\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0874\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0045\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.2699\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0748\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0160\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0130\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.2847\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0168\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0695\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0077\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0040\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0038\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.2415\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0240\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0146\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0152\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0862\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0060\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0045\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0040\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1115\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0126\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.4070\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0434\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0255\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0418\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.9896\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.1696\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/15 [Train]: 100%|█████████▉| 1001/1004 [09:10<00:01,  1.87it/s, loss=0.2145, a_loss=0.1373, d_loss=0.2402]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0744\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0161\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0031\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0026\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0922\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0048\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1548\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0296\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0075\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0065\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.2105\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0105\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0707\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0075\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0034\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0036\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1882\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0172\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0133\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0123\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1052\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0069\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0047\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0053\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1280\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0110\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.3120\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0242\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0174\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0223\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.5071\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/15 [Train]: 100%|██████████| 1004/1004 [09:12<00:00,  1.82it/s, loss=0.3454, a_loss=0.3585, d_loss=0.3411]\n",
            "Epoch 7/15 [Val]: 100%|██████████| 126/126 [00:44<00:00,  2.80it/s, loss=0.3740, a_loss=0.3214, d_loss=0.4266]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/15 Results:\n",
            "  Train Loss: 0.1681 (Arousal: 0.1341, Dominance: 0.1794)\n",
            "  Val Loss: 0.1599 (Arousal: 0.1296, Dominance: 0.1902)\n",
            "  Loss Weights - Arousal: 0.2500, Dominance: 0.7500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/15 [Train]:   0%|          | 1/1004 [00:00<09:54,  1.69it/s, loss=0.3105, a_loss=0.1634, d_loss=0.3596]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.1056\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0235\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0043\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0038\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.1165\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0063\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.2130\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0492\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0115\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0096\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.2677\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0144\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0961\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0112\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0055\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0051\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.2261\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0226\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0131\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0146\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1225\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0089\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0059\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0060\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1231\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0083\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.3719\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0303\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0163\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0321\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.7138\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.1153\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/15 [Train]:  10%|█         | 101/1004 [00:54<07:35,  1.98it/s, loss=0.0685, a_loss=0.0221, d_loss=0.0840]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0375\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0089\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0014\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0014\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0421\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0026\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.0870\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0180\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0050\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0043\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1195\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0055\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0366\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0042\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0022\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0021\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1131\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0091\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0081\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0073\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0581\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0043\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0024\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0035\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.0970\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0126\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.1930\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0110\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0110\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0112\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.2598\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0042\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/15 [Train]:  20%|██        | 201/1004 [01:49<07:04,  1.89it/s, loss=0.1821, a_loss=0.1237, d_loss=0.2015]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0697\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0170\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0033\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0027\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0782\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0045\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.2493\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0648\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0147\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0129\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.2884\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0183\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0647\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0071\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0042\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0038\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.2739\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0266\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0220\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0206\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1132\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0085\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0058\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0076\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1763\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0271\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.5071\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0496\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0242\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0486\n",
            "output_branch_dominance.4.weight: Grad Norm = 1.0712\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.1837\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/15 [Train]:  30%|██▉       | 301/1004 [02:44<06:13,  1.88it/s, loss=0.1612, a_loss=0.0785, d_loss=0.1887]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0564\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0109\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0022\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0020\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0684\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0034\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1353\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0275\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0074\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0062\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1788\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0091\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0589\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0062\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0038\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0032\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1670\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0158\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0146\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0115\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0805\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0057\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0034\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0043\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1200\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0153\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.3289\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0198\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0123\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0191\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.5576\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0339\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/15 [Train]:  40%|███▉      | 401/1004 [03:39<05:02,  1.99it/s, loss=0.2560, a_loss=0.1240, d_loss=0.2999]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0905\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0182\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0037\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0032\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.1034\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0056\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1803\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0360\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0095\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0085\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.2319\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0129\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0839\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0089\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0055\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0046\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.2130\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0205\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0156\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0147\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1246\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0113\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0055\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0078\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1738\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0329\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.3315\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0275\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0162\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0232\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.6913\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/15 [Train]:  50%|████▉     | 501/1004 [04:33<04:24,  1.90it/s, loss=0.0915, a_loss=0.0489, d_loss=0.1057]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0439\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0090\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0018\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0016\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0498\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0024\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1273\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0238\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0071\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0060\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1358\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0069\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0404\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0042\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0023\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0021\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1196\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0109\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0086\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0078\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0539\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0034\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0024\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0027\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.0679\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0064\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2030\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0140\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0082\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0137\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.2877\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/15 [Train]:  60%|█████▉    | 601/1004 [05:28<03:18,  2.03it/s, loss=0.1772, a_loss=0.1270, d_loss=0.1939]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0690\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0143\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0031\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0026\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0773\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0039\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1127\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0258\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0068\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0057\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1352\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0064\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0629\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0066\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0030\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0035\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1356\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0107\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0105\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0092\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0912\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0051\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0035\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0036\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1059\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0008\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2636\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0144\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0137\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0157\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.5032\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/15 [Train]:  70%|██████▉   | 701/1004 [06:23<02:51,  1.77it/s, loss=0.2291, a_loss=0.1592, d_loss=0.2525]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0764\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0150\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0032\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0029\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0799\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0046\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1463\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0288\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0082\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0073\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1822\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0091\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0668\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0072\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0044\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0038\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1694\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0147\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0123\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0117\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0951\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0058\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0035\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0042\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1237\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0069\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2924\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0224\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0166\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0212\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.4784\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/15 [Train]:  80%|███████▉  | 801/1004 [07:17<01:52,  1.81it/s, loss=0.1566, a_loss=0.1001, d_loss=0.1754]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0899\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0188\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0041\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0033\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.1087\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0055\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1613\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0297\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0094\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0077\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.2126\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0116\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0880\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0096\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0044\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0046\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1933\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0184\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0140\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0133\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1036\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0087\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0056\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0055\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1028\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0128\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.3198\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0205\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0144\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0200\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.4091\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0330\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/15 [Train]:  90%|████████▉ | 901/1004 [08:12<00:57,  1.78it/s, loss=0.2429, a_loss=0.1395, d_loss=0.2773]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0701\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0149\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0031\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0027\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0794\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0040\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.2200\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0460\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0130\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0107\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.2385\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0131\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0685\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0071\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0042\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0037\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.2043\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0174\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0145\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0131\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1044\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0073\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0051\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0059\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1548\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0195\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.3589\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0238\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0184\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0234\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.4381\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/15 [Train]: 100%|█████████▉| 1001/1004 [09:08<00:01,  1.59it/s, loss=0.2364, a_loss=0.0974, d_loss=0.2827]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0725\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0191\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0030\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0029\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0802\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0046\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1623\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0432\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0091\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0082\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1912\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0101\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0673\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0073\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0040\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0039\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1644\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0145\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0122\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0113\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0963\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0080\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0056\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0066\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1678\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0232\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2833\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0218\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0124\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0203\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.4226\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0528\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/15 [Train]: 100%|██████████| 1004/1004 [09:09<00:00,  1.83it/s, loss=0.2987, a_loss=0.0291, d_loss=0.3886]\n",
            "Epoch 8/15 [Val]: 100%|██████████| 126/126 [00:44<00:00,  2.81it/s, loss=0.2099, a_loss=0.1610, d_loss=0.2588]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/15 Results:\n",
            "  Train Loss: 0.1706 (Arousal: 0.1335, Dominance: 0.1829)\n",
            "  Val Loss: 0.1611 (Arousal: 0.1222, Dominance: 0.2001)\n",
            "  Loss Weights - Arousal: 0.2500, Dominance: 0.7500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/15 [Train]:   0%|          | 1/1004 [00:00<09:01,  1.85it/s, loss=0.2297, a_loss=0.2077, d_loss=0.2371]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0969\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0181\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0038\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0033\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.1090\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0052\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1355\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0326\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0095\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0071\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1792\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0088\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0869\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0087\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0050\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0046\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1763\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0149\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0139\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0124\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1355\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0099\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0054\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0072\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.2225\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0305\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.3344\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0212\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0163\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0249\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.6797\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0665\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/15 [Train]:  10%|█         | 101/1004 [00:56<08:02,  1.87it/s, loss=0.1340, a_loss=0.1452, d_loss=0.1302]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0907\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0226\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0035\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0035\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0981\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0050\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.2396\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0581\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0127\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0114\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.2302\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0150\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0817\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0079\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0043\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0042\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1909\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0191\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0144\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0143\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1112\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0074\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0041\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0050\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1087\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0068\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.3364\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0329\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0177\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0333\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.7330\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.1315\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/15 [Train]:  20%|██        | 201/1004 [01:51<07:09,  1.87it/s, loss=0.2110, a_loss=0.0729, d_loss=0.2570]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0487\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0120\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0019\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0020\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0583\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0034\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1760\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0429\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0096\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0097\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.2054\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0120\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0482\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0049\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0030\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0030\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1786\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0160\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0126\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0133\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0773\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0071\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0033\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0055\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1749\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0293\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.3162\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0330\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0146\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0312\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.8316\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.1322\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/15 [Train]:  30%|██▉       | 301/1004 [02:47<07:00,  1.67it/s, loss=0.1095, a_loss=0.0436, d_loss=0.1314]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0444\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0082\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0019\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0017\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0525\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0029\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1269\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0227\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0066\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0061\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1609\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0088\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0444\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0046\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0022\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0025\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1576\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0123\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0111\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0116\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0598\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0045\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0026\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0028\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.0743\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0001\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2731\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0283\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0157\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0259\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.6592\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.1122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/15 [Train]:  40%|███▉      | 401/1004 [03:43<06:06,  1.65it/s, loss=0.1485, a_loss=0.2129, d_loss=0.1270]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0772\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0168\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0033\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0029\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0967\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0049\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.0985\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0169\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0059\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0047\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1219\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0059\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0818\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0080\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0064\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0049\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1167\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0102\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0092\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0081\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1203\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0098\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0053\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0071\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1611\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0230\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.1910\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0104\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0067\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0121\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.3456\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0178\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/15 [Train]:  50%|████▉     | 501/1004 [04:37<04:56,  1.70it/s, loss=0.0916, a_loss=0.1669, d_loss=0.0665]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.1162\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0303\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0051\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0045\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.1179\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0077\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1093\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0268\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0068\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0060\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1250\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0077\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0903\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0108\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0057\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0058\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1104\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0106\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0081\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0083\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1377\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0134\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0072\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0104\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.3614\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0550\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.1947\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0180\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0088\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0188\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.5603\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/15 [Train]:  60%|█████▉    | 601/1004 [05:33<03:57,  1.70it/s, loss=0.1249, a_loss=0.1007, d_loss=0.1329]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0654\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0092\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0022\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0022\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0663\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0037\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1120\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0248\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0068\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0054\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1447\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0067\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0566\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0068\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0030\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0029\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1255\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0103\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0086\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0086\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0804\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0048\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0026\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0038\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.0925\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0081\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2439\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0174\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0135\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0205\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.3776\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0513\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/15 [Train]:  70%|██████▉   | 701/1004 [06:27<02:59,  1.69it/s, loss=0.1974, a_loss=0.0811, d_loss=0.2362]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0644\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0135\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0028\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0024\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0651\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0034\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1502\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0336\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0095\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0080\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1810\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0094\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0514\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0053\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0033\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0030\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1725\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0144\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0136\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0128\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0767\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0046\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0031\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0044\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1206\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0105\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.3171\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0185\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0156\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0237\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.6259\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0485\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/15 [Train]:  80%|███████▉  | 801/1004 [07:23<01:55,  1.76it/s, loss=0.1402, a_loss=0.1208, d_loss=0.1466]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0759\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0164\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0031\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0031\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0835\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0052\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1291\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0257\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0081\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0066\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1711\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0084\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0706\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0077\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0042\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0045\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1711\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0149\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0129\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0119\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1035\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0094\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0046\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0063\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1751\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0229\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2526\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0185\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0143\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0157\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.3878\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0236\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/15 [Train]:  90%|████████▉ | 901/1004 [08:18<00:54,  1.88it/s, loss=0.1355, a_loss=0.1648, d_loss=0.1257]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0812\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0191\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0037\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0034\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0916\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0055\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1045\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0213\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0058\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0052\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1300\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0069\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0726\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0076\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0040\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0043\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1167\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0106\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0089\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0087\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1193\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0111\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0071\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0093\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.2788\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0414\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.1952\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0113\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0086\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0123\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.2765\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/15 [Train]: 100%|█████████▉| 1001/1004 [09:13<00:01,  1.86it/s, loss=0.3031, a_loss=0.2789, d_loss=0.3111]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.1272\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0239\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0044\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0045\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.1131\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0072\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1736\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0438\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0100\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0091\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1964\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0109\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0901\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0111\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0057\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0052\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1718\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0159\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0119\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0128\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1168\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0090\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0054\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0073\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.2297\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0264\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2872\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0209\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0198\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0267\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.6028\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/15 [Train]: 100%|██████████| 1004/1004 [09:15<00:00,  1.81it/s, loss=0.0989, a_loss=0.0440, d_loss=0.1171]\n",
            "Epoch 9/15 [Val]: 100%|██████████| 126/126 [00:44<00:00,  2.80it/s, loss=0.2968, a_loss=0.1694, d_loss=0.4243]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/15 Results:\n",
            "  Train Loss: 0.1658 (Arousal: 0.1269, Dominance: 0.1788)\n",
            "  Val Loss: 0.1460 (Arousal: 0.1099, Dominance: 0.1821)\n",
            "  Loss Weights - Arousal: 0.2500, Dominance: 0.7500\n",
            "  Saved best model (val_loss: 0.1460)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/15 [Train]:   0%|          | 1/1004 [00:00<15:06,  1.11it/s, loss=0.2754, a_loss=0.1738, d_loss=0.3092]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0850\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0156\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0032\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0029\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0925\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0044\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.2038\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0440\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0125\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0115\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.2482\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0161\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0739\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0079\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0041\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0039\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.2386\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0211\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0190\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0190\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1053\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0063\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0044\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0047\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1307\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0106\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.4728\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0473\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0273\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0515\n",
            "output_branch_dominance.4.weight: Grad Norm = 1.4011\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.2090\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/15 [Train]:  10%|█         | 101/1004 [00:55<08:12,  1.83it/s, loss=0.1290, a_loss=0.0585, d_loss=0.1526]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0470\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0107\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0017\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0018\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0495\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0031\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1157\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0265\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0066\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0054\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1362\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0068\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0408\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0045\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0027\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0025\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1206\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0101\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0106\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0090\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0722\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0061\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0035\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0051\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1787\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0250\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2379\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0162\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0102\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0187\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.4511\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/15 [Train]:  20%|██        | 201/1004 [01:50<07:06,  1.88it/s, loss=0.1922, a_loss=0.0741, d_loss=0.2316]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0843\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0194\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0033\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0034\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0851\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0052\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1565\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0309\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0094\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0081\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1720\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0088\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0684\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0083\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0039\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0039\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1505\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0121\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0101\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0103\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0788\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0054\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0039\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0042\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.0973\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0078\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2805\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0225\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0146\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0241\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.5348\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0967\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/15 [Train]:  30%|██▉       | 301/1004 [02:46<06:50,  1.71it/s, loss=0.1153, a_loss=0.0932, d_loss=0.1227]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0683\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0142\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0027\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0026\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0639\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0037\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1124\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0235\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0063\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0059\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1265\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0071\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0517\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0056\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0032\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0030\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1114\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0096\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0083\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0081\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0840\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0060\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0032\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0056\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1478\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0148\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2239\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0183\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0135\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0230\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.6869\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.1012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/15 [Train]:  40%|███▉      | 401/1004 [03:41<05:06,  1.97it/s, loss=0.2851, a_loss=0.1101, d_loss=0.3435]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0691\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0145\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0032\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0028\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0810\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0042\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1457\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0332\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0088\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0073\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1705\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0084\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0736\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0074\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0048\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0042\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1564\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0133\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0118\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0110\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0967\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0074\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0066\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0070\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1450\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0247\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2746\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0157\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0174\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0178\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.4584\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0183\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/15 [Train]:  50%|████▉     | 501/1004 [04:36<04:40,  1.80it/s, loss=0.1428, a_loss=0.0300, d_loss=0.1805]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0316\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0069\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0013\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0012\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0337\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0019\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1290\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0319\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0074\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0067\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1598\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0087\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0279\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0030\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0017\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0016\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1537\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0128\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0108\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0115\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0460\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0035\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0026\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0029\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.0946\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0129\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2538\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0207\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0138\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0205\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.6921\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/15 [Train]:  60%|█████▉    | 601/1004 [05:31<03:27,  1.95it/s, loss=0.1982, a_loss=0.1208, d_loss=0.2240]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0602\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0135\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0027\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0024\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0714\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0040\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1493\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0332\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0092\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0084\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1821\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0099\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0605\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0063\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0038\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0036\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1612\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0154\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0134\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0119\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1049\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0087\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0060\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0076\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.2352\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0302\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2575\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0162\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0124\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0179\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.3573\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0237\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/15 [Train]:  70%|██████▉   | 701/1004 [06:26<02:43,  1.85it/s, loss=0.2326, a_loss=0.1981, d_loss=0.2441]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0810\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0155\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0032\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0031\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0838\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0052\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1276\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0241\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0071\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0063\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1679\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0095\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0703\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0080\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0046\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0043\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1604\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0158\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0119\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0122\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1081\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0074\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0049\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0063\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.2062\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0264\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.3178\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0205\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0160\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0223\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.5927\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0659\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/15 [Train]:  80%|███████▉  | 801/1004 [07:21<01:44,  1.93it/s, loss=0.0765, a_loss=0.1525, d_loss=0.0511]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0902\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0170\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0038\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0032\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0947\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0060\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.0807\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0165\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0043\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0041\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.0899\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0050\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0825\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0094\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0054\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0049\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.0781\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0066\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0050\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0055\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1210\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0125\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0067\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0096\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.2824\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0437\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.1410\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0108\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0080\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0126\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.4070\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/15 [Train]:  90%|████████▉ | 901/1004 [08:16<00:52,  1.98it/s, loss=0.1393, a_loss=0.1121, d_loss=0.1484]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0554\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0122\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0025\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0024\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0614\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0035\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1285\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0273\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0075\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0073\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1412\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0082\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0506\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0056\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0033\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0033\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1200\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0112\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0097\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0093\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0741\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0048\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0039\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0042\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1091\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0075\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2280\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0168\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0134\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0172\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.4580\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/15 [Train]: 100%|█████████▉| 1001/1004 [09:11<00:01,  1.94it/s, loss=0.2443, a_loss=0.0728, d_loss=0.3014]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0523\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0136\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0022\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0021\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0579\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0034\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1642\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0390\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0102\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0079\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1801\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0088\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0479\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0050\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0029\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0029\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1695\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0134\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0131\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0121\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0735\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0058\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0041\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0049\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1407\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0146\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2763\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0170\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0179\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0183\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.3361\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/15 [Train]: 100%|██████████| 1004/1004 [09:13<00:00,  1.82it/s, loss=0.1353, a_loss=0.1815, d_loss=0.1199]\n",
            "Epoch 10/15 [Val]: 100%|██████████| 126/126 [00:45<00:00,  2.80it/s, loss=0.3531, a_loss=0.2773, d_loss=0.4289]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/15 Results:\n",
            "  Train Loss: 0.1619 (Arousal: 0.1233, Dominance: 0.1748)\n",
            "  Val Loss: 0.1447 (Arousal: 0.1108, Dominance: 0.1787)\n",
            "  Loss Weights - Arousal: 0.2500, Dominance: 0.7500\n",
            "  Saved best model (val_loss: 0.1447)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/15 [Train]:   0%|          | 1/1004 [00:00<09:03,  1.85it/s, loss=0.2436, a_loss=0.0973, d_loss=0.2924]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0654\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0161\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0028\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0025\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0715\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0040\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1824\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0519\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0103\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0095\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.2030\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0107\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0576\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0060\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0035\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0030\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1856\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0160\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0140\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0137\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0822\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0073\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0051\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0062\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1459\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0262\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.3039\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0208\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0162\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0214\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.4130\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/15 [Train]:  10%|█         | 101/1004 [00:56<08:23,  1.79it/s, loss=0.2403, a_loss=0.2489, d_loss=0.2374]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.1020\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0214\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0043\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0037\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.1014\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0057\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1625\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0293\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0081\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0077\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1676\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0085\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0840\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0099\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0051\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0048\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1531\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0149\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0098\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0107\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1229\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0088\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0053\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0069\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.2211\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0225\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2725\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0199\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0142\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0216\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.5122\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0680\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/15 [Train]:  20%|██        | 201/1004 [01:51<07:03,  1.89it/s, loss=0.1220, a_loss=0.1783, d_loss=0.1032]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.1055\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0215\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0039\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0040\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.1057\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0067\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.0790\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0179\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0048\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0043\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1050\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0060\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0834\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0098\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0055\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0050\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1036\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0094\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0080\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0076\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1380\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0142\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0084\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0120\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.2998\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0629\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2189\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0151\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0116\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0154\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.3463\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/15 [Train]:  30%|██▉       | 301/1004 [02:45<06:17,  1.86it/s, loss=0.2954, a_loss=0.1725, d_loss=0.3364]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.1015\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0197\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0040\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0034\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.1112\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0053\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1674\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0361\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0087\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0086\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1803\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0103\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0881\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0090\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0045\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0047\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1539\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0131\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0110\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0115\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1104\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0093\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0045\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0061\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1380\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0056\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.3035\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0240\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0142\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0270\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.6947\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0856\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/15 [Train]:  40%|███▉      | 401/1004 [03:41<05:04,  1.98it/s, loss=0.1183, a_loss=0.0302, d_loss=0.1476]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0369\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0082\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0016\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0015\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0392\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0024\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1326\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0307\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0068\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0060\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1321\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0062\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0323\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0037\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0017\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0018\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1317\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0116\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0098\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0096\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0458\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0031\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0025\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0026\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.0581\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0044\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.1943\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0123\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0095\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0120\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.3325\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0077\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/15 [Train]:  50%|████▉     | 501/1004 [04:35<04:39,  1.80it/s, loss=0.1531, a_loss=0.1972, d_loss=0.1384]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0590\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0141\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0023\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0022\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0685\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0034\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1277\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0276\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0076\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0066\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1428\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0079\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0588\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0060\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0040\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0035\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1383\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0120\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0107\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0103\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0925\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0055\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0046\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0047\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1366\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0045\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2207\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0115\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0107\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0133\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.3296\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0118\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/15 [Train]:  60%|█████▉    | 601/1004 [05:30<03:47,  1.77it/s, loss=0.1304, a_loss=0.1079, d_loss=0.1379]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0636\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0118\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0026\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0022\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0619\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0038\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1102\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0224\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0061\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0058\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1226\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0069\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0489\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0056\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0031\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0029\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1170\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0101\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0086\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0094\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0925\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0080\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0046\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0068\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.2143\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0362\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2278\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0180\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0116\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0216\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.6574\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/15 [Train]:  70%|██████▉   | 701/1004 [06:26<03:24,  1.48it/s, loss=0.1830, a_loss=0.0604, d_loss=0.2239]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0532\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0108\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0019\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0020\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0547\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0032\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1300\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0300\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0083\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0067\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1623\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0084\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0478\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0050\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0028\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0027\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1452\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0123\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0099\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0116\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0652\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0054\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0032\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0040\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1353\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0189\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2442\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0161\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0133\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0186\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.4769\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/15 [Train]:  80%|███████▉  | 801/1004 [07:21<02:05,  1.62it/s, loss=0.1664, a_loss=0.1294, d_loss=0.1788]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0783\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0197\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0035\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0029\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0794\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0042\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1514\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0331\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0097\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0081\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1589\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0102\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0667\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0071\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0037\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0038\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1576\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0153\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0137\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0124\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0973\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0079\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0056\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0062\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1693\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0266\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2547\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0184\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0118\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0190\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.4705\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0522\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/15 [Train]:  90%|████████▉ | 901/1004 [08:16<00:59,  1.72it/s, loss=0.0928, a_loss=0.0660, d_loss=0.1017]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0562\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0155\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0023\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0022\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0547\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0032\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1164\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0254\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0054\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0050\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1238\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0053\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0444\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0052\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0026\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0025\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1083\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0089\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0077\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0071\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0672\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0048\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0033\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0042\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1059\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0096\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.1738\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0116\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0094\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0129\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.2033\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0327\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/15 [Train]: 100%|█████████▉| 1001/1004 [09:11<00:01,  1.88it/s, loss=0.2096, a_loss=0.1510, d_loss=0.2292]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0898\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0232\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0037\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0032\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0846\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0041\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1305\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0272\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0065\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0060\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1307\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0068\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0709\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0070\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0042\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0042\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1146\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0107\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0088\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0085\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0884\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0059\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0041\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0045\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1081\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0068\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.1894\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0103\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0119\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0131\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.3644\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0246\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/15 [Train]: 100%|██████████| 1004/1004 [09:13<00:00,  1.81it/s, loss=0.1476, a_loss=0.0850, d_loss=0.1685]\n",
            "Epoch 11/15 [Val]: 100%|██████████| 126/126 [00:45<00:00,  2.79it/s, loss=0.3495, a_loss=0.1880, d_loss=0.5110]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/15 Results:\n",
            "  Train Loss: 0.1554 (Arousal: 0.1183, Dominance: 0.1678)\n",
            "  Val Loss: 0.1429 (Arousal: 0.1025, Dominance: 0.1833)\n",
            "  Loss Weights - Arousal: 0.2500, Dominance: 0.7500\n",
            "  Saved best model (val_loss: 0.1429)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/15 [Train]:   0%|          | 1/1004 [00:00<08:52,  1.88it/s, loss=0.2654, a_loss=0.2000, d_loss=0.2872]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0872\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0181\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0035\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0033\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0897\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0052\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1568\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0326\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0083\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0078\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1584\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0090\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0774\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0087\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0045\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0044\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1515\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0138\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0129\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0121\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1035\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0081\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0043\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0060\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1268\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0151\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2783\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0209\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0104\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0248\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.5688\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0960\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/15 [Train]:  10%|█         | 101/1004 [00:56<08:36,  1.75it/s, loss=0.1375, a_loss=0.1125, d_loss=0.1458]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0679\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0120\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0029\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0023\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0758\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0036\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1488\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0418\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0075\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0073\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1523\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0082\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0661\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0061\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0039\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0037\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1376\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0128\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0105\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0097\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0937\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0071\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0039\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0052\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1162\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0141\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2011\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0132\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0100\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0148\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.4419\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/15 [Train]:  20%|██        | 201/1004 [01:51<07:56,  1.69it/s, loss=0.1075, a_loss=0.1869, d_loss=0.0810]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0834\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0188\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0030\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0032\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0830\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0052\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1140\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0261\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0066\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0060\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1214\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0067\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0657\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0076\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0038\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0038\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1097\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0091\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0085\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0082\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0929\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0085\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0049\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0064\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1735\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0320\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.1773\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0153\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0091\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0142\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.3197\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/15 [Train]:  30%|██▉       | 301/1004 [02:46<06:48,  1.72it/s, loss=0.2052, a_loss=0.1020, d_loss=0.2396]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0700\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0216\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0027\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0027\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0719\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0040\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1448\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0335\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0079\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0071\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1574\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0074\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0649\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0071\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0037\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0036\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1440\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0114\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0100\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0103\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0838\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0057\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0043\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0043\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.0996\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0038\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2470\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0169\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0148\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0188\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.5694\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/15 [Train]:  40%|███▉      | 401/1004 [03:42<05:35,  1.80it/s, loss=0.2155, a_loss=0.1552, d_loss=0.2356]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0700\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0140\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0032\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0027\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0819\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0041\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1586\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0286\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0084\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0073\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1617\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0081\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0683\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0075\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0039\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0039\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1510\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0127\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0128\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0108\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0922\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0053\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0035\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0040\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.0957\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0056\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2399\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0148\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0156\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0178\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.4471\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/15 [Train]:  50%|████▉     | 501/1004 [04:37<04:08,  2.02it/s, loss=0.1179, a_loss=0.1361, d_loss=0.1118]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0757\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0167\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0034\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0028\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0910\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0046\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1377\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0327\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0082\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0074\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1306\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0074\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0745\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0074\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0047\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0046\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1205\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0116\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0092\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0092\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1049\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0079\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0044\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0058\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1726\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0153\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.1879\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0134\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0078\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0123\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.3790\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/15 [Train]:  60%|█████▉    | 601/1004 [05:33<03:38,  1.84it/s, loss=0.1231, a_loss=0.2168, d_loss=0.0919]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.1106\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0280\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0043\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0046\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.1134\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0075\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1234\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0363\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0078\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0064\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1339\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0074\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0900\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0119\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0052\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0052\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1190\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0103\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0090\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0086\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1196\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0107\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0053\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0085\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.2170\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0319\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.1863\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0145\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0103\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0164\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.3375\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0510\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/15 [Train]:  70%|██████▉   | 701/1004 [06:28<02:51,  1.76it/s, loss=0.1321, a_loss=0.1038, d_loss=0.1415]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0669\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0124\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0026\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0023\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0638\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0029\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1082\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0168\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0055\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0052\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1286\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0060\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0534\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0050\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0035\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0027\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1211\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0110\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0092\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0081\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0759\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0047\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0027\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0040\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1091\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0037\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2102\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0138\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0099\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0132\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.2636\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0153\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/15 [Train]:  80%|███████▉  | 801/1004 [07:22<01:49,  1.85it/s, loss=0.1932, a_loss=0.2122, d_loss=0.1869]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0913\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0170\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0035\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0032\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0986\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0055\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1612\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0326\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0098\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0089\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1777\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0100\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0853\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0091\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0050\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0050\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1728\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0146\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0133\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0130\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1217\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0096\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0052\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0074\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.2255\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0252\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2933\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0236\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0140\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0240\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.6622\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0865\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/15 [Train]:  90%|████████▉ | 901/1004 [08:18<00:57,  1.79it/s, loss=0.0734, a_loss=0.1557, d_loss=0.0459]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0579\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0133\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0025\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0022\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0658\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0033\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.0705\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0137\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0039\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0035\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.0778\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0042\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0592\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0057\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0036\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0036\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.0674\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0067\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0047\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0049\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0935\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0065\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0041\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0048\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1465\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0096\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.1196\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0076\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0063\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0081\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.1977\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0170\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/15 [Train]: 100%|█████████▉| 1001/1004 [09:15<00:01,  1.60it/s, loss=0.2070, a_loss=0.1954, d_loss=0.2108]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0685\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0161\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0026\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0025\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0770\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0036\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1825\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0416\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0091\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0087\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1661\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0087\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0577\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0060\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0035\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0032\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1409\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0131\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0106\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0100\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0872\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0059\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0033\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0049\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1049\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0078\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2453\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0191\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0102\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0209\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.4244\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0746\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/15 [Train]: 100%|██████████| 1004/1004 [09:17<00:00,  1.80it/s, loss=0.1806, a_loss=0.0770, d_loss=0.2152]\n",
            "Epoch 12/15 [Val]: 100%|██████████| 126/126 [00:45<00:00,  2.79it/s, loss=0.3088, a_loss=0.1785, d_loss=0.4391]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/15 Results:\n",
            "  Train Loss: 0.1538 (Arousal: 0.1164, Dominance: 0.1663)\n",
            "  Val Loss: 0.1394 (Arousal: 0.1030, Dominance: 0.1758)\n",
            "  Loss Weights - Arousal: 0.2500, Dominance: 0.7500\n",
            "  Saved best model (val_loss: 0.1394)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/15 [Train]:   0%|          | 1/1004 [00:00<09:06,  1.83it/s, loss=0.2851, a_loss=0.0412, d_loss=0.3664]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0414\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0104\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0015\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0014\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0417\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0020\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1521\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0355\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0077\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0072\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1546\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0074\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0331\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0033\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0019\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0018\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1373\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0124\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0102\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0095\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0448\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0026\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0016\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0021\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.0537\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0043\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2460\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0126\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0098\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0166\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.2918\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0451\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/15 [Train]:  10%|█         | 101/1004 [00:55<07:56,  1.89it/s, loss=0.1007, a_loss=0.0708, d_loss=0.1107]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0528\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0120\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0020\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0020\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0548\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0032\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1371\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0295\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0067\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0065\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1294\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0082\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0433\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0048\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0024\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0025\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1125\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0112\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0080\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0084\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0619\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0047\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0031\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0038\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1408\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0158\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2029\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0193\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0106\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0199\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.5578\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0848\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/15 [Train]:  20%|██        | 201/1004 [01:51<07:14,  1.85it/s, loss=0.1571, a_loss=0.1002, d_loss=0.1761]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0824\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0221\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0030\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0030\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0814\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0048\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1355\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0389\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0073\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0064\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1399\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0060\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0671\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0075\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0033\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0037\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1248\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0098\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0082\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0090\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0892\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0081\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0046\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0065\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1996\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0315\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2143\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0141\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0109\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0186\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.4138\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0644\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/15 [Train]:  30%|██▉       | 301/1004 [02:47<06:12,  1.89it/s, loss=0.1309, a_loss=0.1042, d_loss=0.1398]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0695\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0127\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0026\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0024\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0735\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0044\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1233\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0229\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0069\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0062\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1389\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0072\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0603\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0067\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0043\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0037\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1334\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0113\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0101\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0105\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0942\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0070\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0044\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0060\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1520\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0200\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2061\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0139\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0103\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0162\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.5787\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0518\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/15 [Train]:  40%|███▉      | 401/1004 [03:42<06:01,  1.67it/s, loss=0.1615, a_loss=0.1216, d_loss=0.1748]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0999\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0253\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0036\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0039\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.1028\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0069\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1591\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0312\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0072\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0065\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1350\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0052\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0860\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0102\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0043\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0053\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1221\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0097\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0085\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0086\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1201\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0132\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0065\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0099\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.2857\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0493\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2042\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0153\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0110\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0170\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.5220\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0607\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/15 [Train]:  50%|████▉     | 501/1004 [04:37<05:03,  1.66it/s, loss=0.2197, a_loss=0.1123, d_loss=0.2554]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0535\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0102\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0021\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0019\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0575\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0031\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1825\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0372\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0098\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0090\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1702\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0103\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0491\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0052\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0029\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0029\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1495\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0138\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0113\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0117\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0675\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0049\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0027\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0038\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1025\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0078\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2621\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0181\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0111\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0227\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.6441\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0700\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/15 [Train]:  60%|█████▉    | 601/1004 [05:33<03:54,  1.72it/s, loss=0.1357, a_loss=0.0673, d_loss=0.1585]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0436\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0110\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0016\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0016\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0465\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0024\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1008\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0261\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0047\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0049\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1216\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0050\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0369\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0037\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0021\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0022\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1187\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0094\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0102\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0089\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0594\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0045\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0028\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0039\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.0955\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0144\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2215\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0147\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0105\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0162\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.3249\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0137\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/15 [Train]:  70%|██████▉   | 701/1004 [06:28<02:44,  1.84it/s, loss=0.1340, a_loss=0.0834, d_loss=0.1508]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0843\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0147\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0032\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0029\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0764\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0047\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1503\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0303\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0070\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0073\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1681\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0099\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0571\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0077\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0032\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0030\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1680\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0145\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0120\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0123\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0811\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0056\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0035\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0046\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1189\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0165\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2924\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0308\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0184\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0325\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.9087\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.1511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/15 [Train]:  80%|███████▉  | 801/1004 [07:24<01:49,  1.85it/s, loss=0.2353, a_loss=0.1522, d_loss=0.2630]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.1240\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0237\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0045\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0045\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.1065\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0076\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1727\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0384\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0102\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0092\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.2002\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0118\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0874\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0108\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0056\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0054\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1807\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0176\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0133\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0149\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1189\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0127\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0058\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0091\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.3009\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0502\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.3113\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0209\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0175\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0238\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.4971\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0246\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/15 [Train]:  90%|████████▉ | 901/1004 [08:21<00:54,  1.88it/s, loss=0.1318, a_loss=0.1155, d_loss=0.1372]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0545\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0123\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0025\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0021\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0646\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0033\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.0832\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0164\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0049\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0043\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.0905\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0048\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0554\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0054\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0040\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0032\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.0825\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0063\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0068\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0065\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0800\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0049\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0034\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0040\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.0831\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0032\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.1659\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0133\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0087\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0168\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.5856\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0766\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/15 [Train]: 100%|█████████▉| 1001/1004 [09:16<00:01,  1.84it/s, loss=0.1722, a_loss=0.1440, d_loss=0.1816]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0716\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0163\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0026\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0028\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0778\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0051\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1224\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0243\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0077\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0062\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1393\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0068\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0655\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0073\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0042\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0041\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1356\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0097\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0092\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0098\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.1082\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0106\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0061\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0093\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.2946\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0474\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2584\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0270\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0144\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0290\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.6933\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.1214\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/15 [Train]: 100%|██████████| 1004/1004 [09:18<00:00,  1.80it/s, loss=0.1678, a_loss=0.1330, d_loss=0.1795]\n",
            "Epoch 13/15 [Val]: 100%|██████████| 126/126 [00:45<00:00,  2.79it/s, loss=0.1794, a_loss=0.0901, d_loss=0.2687]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/15 Results:\n",
            "  Train Loss: 0.1544 (Arousal: 0.1184, Dominance: 0.1664)\n",
            "  Val Loss: 0.1815 (Arousal: 0.1421, Dominance: 0.2209)\n",
            "  Loss Weights - Arousal: 0.2500, Dominance: 0.7500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/15 [Train]:   0%|          | 1/1004 [00:00<10:11,  1.64it/s, loss=0.0997, a_loss=0.1625, d_loss=0.0787]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0834\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0136\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0031\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0027\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0762\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0037\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.0727\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0156\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0046\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0044\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.0962\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0054\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0606\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0060\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0034\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0032\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.0900\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0076\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0075\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0068\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0820\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0049\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0032\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0043\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1156\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0104\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.1530\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0115\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0084\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0111\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.2780\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0183\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/15 [Train]:  10%|█         | 101/1004 [00:56<08:12,  1.83it/s, loss=0.0778, a_loss=0.0944, d_loss=0.0723]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0520\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0098\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0023\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0018\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0555\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0024\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.0818\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0201\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0051\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0047\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.0982\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0059\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0478\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0047\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0033\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0027\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.0938\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0082\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0075\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0074\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0787\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0050\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0039\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0043\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1137\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0003\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.1806\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0149\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0123\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0175\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.5386\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0686\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/15 [Train]:  20%|██        | 201/1004 [01:51<06:52,  1.94it/s, loss=0.1316, a_loss=0.1644, d_loss=0.1207]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0500\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0111\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0023\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0019\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0575\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0028\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.0864\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0212\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0048\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0040\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.0953\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0041\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0501\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0048\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0035\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0027\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.0942\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0072\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0078\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0073\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0803\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0050\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0041\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0042\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1234\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0028\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.1614\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0098\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0088\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0110\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.2156\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0028\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/15 [Train]:  30%|██▉       | 301/1004 [02:46<06:20,  1.85it/s, loss=0.2739, a_loss=0.1674, d_loss=0.3094]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0781\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0191\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0035\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0031\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0838\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0042\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1245\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0284\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0077\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0069\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1343\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0074\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0714\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0071\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0041\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0043\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1309\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0111\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0116\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0109\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0976\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0079\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0044\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0055\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1300\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0033\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2634\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0181\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0126\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0249\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.7556\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0867\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/15 [Train]:  40%|███▉      | 401/1004 [03:42<05:23,  1.87it/s, loss=0.1407, a_loss=0.0740, d_loss=0.1629]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0464\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0084\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0017\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0016\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0474\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0025\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.0964\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0175\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0054\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0049\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1357\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0059\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0420\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0044\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0029\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0024\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1376\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0102\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0114\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0095\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0634\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0050\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0035\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0044\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1041\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0159\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2666\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0186\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0175\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0193\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.3463\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0594\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/15 [Train]:  50%|████▉     | 501/1004 [04:38<04:23,  1.91it/s, loss=0.0964, a_loss=0.1151, d_loss=0.0901]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0574\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0122\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0023\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0021\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0595\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0030\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1066\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0195\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0065\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0056\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1076\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0049\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0499\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0051\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0034\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0028\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.0957\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0073\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0072\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0068\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0812\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0046\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0039\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0039\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.0807\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0031\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.1641\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0123\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0090\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0144\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.3463\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/15 [Train]:  60%|█████▉    | 601/1004 [05:34<03:41,  1.82it/s, loss=0.1520, a_loss=0.0910, d_loss=0.1723]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.1009\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0178\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0036\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0034\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0890\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0054\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1007\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0184\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0057\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0051\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1190\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0046\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0719\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0080\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0043\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0041\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1161\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0082\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0092\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0081\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0877\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0060\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0037\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0044\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.0982\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0112\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.1818\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0111\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0077\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0120\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.3060\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/15 [Train]:  70%|██████▉   | 701/1004 [06:30<02:36,  1.94it/s, loss=0.0776, a_loss=0.0807, d_loss=0.0766]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0627\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0116\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0027\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0022\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0617\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0030\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1139\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0245\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0065\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0058\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1112\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0056\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0495\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0050\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0031\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0026\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.0982\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0076\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0074\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0078\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0626\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0031\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0032\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0026\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.0779\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0036\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.1592\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0116\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0078\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0118\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.2582\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0309\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/15 [Train]:  80%|███████▉  | 801/1004 [07:26<01:56,  1.74it/s, loss=0.1093, a_loss=0.1197, d_loss=0.1058]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0648\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0137\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0025\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0025\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0607\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0038\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.0746\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0137\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0041\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0037\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.0816\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0040\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0518\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0054\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0036\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0033\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.0768\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0067\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0069\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0061\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0717\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0064\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0039\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0053\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.2314\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0301\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.1523\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0078\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0063\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0098\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.2843\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0041\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/15 [Train]:  90%|████████▉ | 901/1004 [08:22<01:06,  1.54it/s, loss=0.1583, a_loss=0.0732, d_loss=0.1866]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0487\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0128\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0020\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0019\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0512\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0026\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1030\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0258\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0057\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0058\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1185\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0069\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0422\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0045\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0026\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0025\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1157\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0101\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0107\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0094\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0561\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0033\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0025\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0027\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.0717\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0010\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2141\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0156\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0135\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0192\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.5510\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0518\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/15 [Train]: 100%|█████████▉| 1001/1004 [09:19<00:01,  1.71it/s, loss=0.1293, a_loss=0.0956, d_loss=0.1406]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0630\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0144\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0020\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0023\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0588\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0038\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1163\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0257\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0064\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0056\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1115\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0047\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0471\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0050\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0028\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0030\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1054\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0082\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0096\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0081\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0842\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0076\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0035\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0067\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.2168\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0334\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.1851\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0108\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0096\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0116\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.2537\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/15 [Train]: 100%|██████████| 1004/1004 [09:20<00:00,  1.79it/s, loss=0.1387, a_loss=0.1262, d_loss=0.1429]\n",
            "Epoch 14/15 [Val]: 100%|██████████| 126/126 [00:45<00:00,  2.79it/s, loss=0.2594, a_loss=0.1245, d_loss=0.3943]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/15 Results:\n",
            "  Train Loss: 0.1600 (Arousal: 0.1211, Dominance: 0.1730)\n",
            "  Val Loss: 0.1471 (Arousal: 0.1106, Dominance: 0.1836)\n",
            "  Loss Weights - Arousal: 0.2500, Dominance: 0.7500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/15 [Train]:   0%|          | 1/1004 [00:00<09:28,  1.76it/s, loss=0.2370, a_loss=0.0678, d_loss=0.2934]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0347\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0065\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0013\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0013\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0353\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0019\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1747\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0368\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0101\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0096\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1607\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0094\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0305\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0031\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0020\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0018\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1411\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0126\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0118\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0113\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0588\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0043\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0027\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0042\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1319\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0199\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2213\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0144\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0100\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0193\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.5849\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/15 [Train]:  10%|█         | 101/1004 [00:56<07:43,  1.95it/s, loss=0.1715, a_loss=0.1502, d_loss=0.1786]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0770\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0149\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0029\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0026\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0686\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0029\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1550\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0347\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0088\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0080\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1298\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0075\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0577\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0056\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0033\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0033\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1167\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0108\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0105\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0092\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0862\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0053\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0032\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0051\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1625\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0169\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2088\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0138\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0108\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0165\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.3922\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/15 [Train]:  20%|██        | 201/1004 [01:52<07:21,  1.82it/s, loss=0.1525, a_loss=0.0794, d_loss=0.1769]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0600\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0108\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0022\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0020\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0535\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0030\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1291\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0349\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0076\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0070\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1390\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0075\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0419\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0050\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0029\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0023\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1194\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0105\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0106\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0095\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0668\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0039\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0030\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0033\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.0952\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0033\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2039\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0151\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0094\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0170\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.5587\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0587\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/15 [Train]:  30%|██▉       | 301/1004 [02:47<07:35,  1.54it/s, loss=0.1388, a_loss=0.0620, d_loss=0.1644]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0554\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0135\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0026\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0022\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0585\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0033\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1333\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0268\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0073\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0066\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1219\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0068\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0478\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0047\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0027\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0029\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1073\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0095\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0084\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0085\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0679\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0057\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0040\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0051\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1354\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0194\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2273\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0174\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0120\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0200\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.4686\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0599\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/15 [Train]:  40%|███▉      | 401/1004 [03:43<06:18,  1.59it/s, loss=0.2130, a_loss=0.0259, d_loss=0.2753]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0435\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0099\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0017\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0015\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0396\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0021\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1984\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0472\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0120\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0100\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1937\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0113\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0323\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0033\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0018\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0018\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1754\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0155\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0143\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0149\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0413\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0026\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0018\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0018\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.0544\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0033\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2912\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0216\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0154\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0260\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.5068\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0793\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/15 [Train]:  50%|████▉     | 501/1004 [04:38<04:38,  1.81it/s, loss=0.1550, a_loss=0.0972, d_loss=0.1743]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0522\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0093\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0020\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0020\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0522\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0030\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.2004\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0428\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0111\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0102\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1752\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0098\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0457\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0048\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0029\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0027\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1478\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0133\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0124\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0117\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0717\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0053\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0035\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0049\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1380\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0139\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2361\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0178\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0125\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0220\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.7643\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0791\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/15 [Train]:  60%|█████▉    | 601/1004 [05:34<03:51,  1.74it/s, loss=0.1328, a_loss=0.1651, d_loss=0.1220]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0747\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0140\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0031\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0029\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0674\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0043\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.0928\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0155\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0049\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0047\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.0993\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0057\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0558\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0059\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0038\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0035\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.0874\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0075\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0085\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0073\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0904\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0077\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0047\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0070\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.2198\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0384\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.1782\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0146\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0067\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0186\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.5520\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/15 [Train]:  70%|██████▉   | 701/1004 [06:30<02:47,  1.81it/s, loss=0.1091, a_loss=0.0529, d_loss=0.1278]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0423\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0083\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0018\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0016\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0456\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0021\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.0984\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0208\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0061\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0053\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1039\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0050\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0392\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0036\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0028\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0024\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.0985\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0079\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0087\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0075\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0514\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0037\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0023\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0029\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.0736\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0113\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.1608\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0109\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0098\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0138\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.3594\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/15 [Train]:  80%|███████▉  | 801/1004 [07:26<01:39,  2.04it/s, loss=0.3047, a_loss=0.1272, d_loss=0.3639]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0514\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0108\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0023\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0019\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0549\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0026\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1589\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0396\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0100\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0097\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1644\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0105\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0511\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0046\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0038\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0031\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1563\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0134\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0130\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0128\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0745\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0053\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0040\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0047\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1367\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0205\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2767\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0187\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0137\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0240\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.7456\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/15 [Train]:  90%|████████▉ | 901/1004 [08:20<00:54,  1.88it/s, loss=0.2197, a_loss=0.0917, d_loss=0.2623]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0520\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0127\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0022\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0021\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0567\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0033\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1382\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0263\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0081\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0077\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1366\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0090\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0494\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0050\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0030\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0032\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1267\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0105\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0104\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0105\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0871\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0074\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0046\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0068\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.2026\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0347\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2536\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0211\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0133\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0287\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.9879\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.1402\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/15 [Train]: 100%|█████████▉| 1001/1004 [09:15<00:01,  1.98it/s, loss=0.1470, a_loss=0.0749, d_loss=0.1710]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusion_layer_arousal.0.weight: Grad Norm = 0.0662\n",
            "fusion_layer_arousal.0.bias: Grad Norm = 0.0143\n",
            "fusion_layer_arousal.1.weight: Grad Norm = 0.0030\n",
            "fusion_layer_arousal.1.bias: Grad Norm = 0.0026\n",
            "fusion_layer_arousal.4.weight: Grad Norm = 0.0608\n",
            "fusion_layer_arousal.4.bias: Grad Norm = 0.0036\n",
            "fusion_layer_dominance.0.weight: Grad Norm = 0.1021\n",
            "fusion_layer_dominance.0.bias: Grad Norm = 0.0148\n",
            "fusion_layer_dominance.1.weight: Grad Norm = 0.0057\n",
            "fusion_layer_dominance.1.bias: Grad Norm = 0.0052\n",
            "fusion_layer_dominance.4.weight: Grad Norm = 0.1136\n",
            "fusion_layer_dominance.4.bias: Grad Norm = 0.0056\n",
            "shared_fc_arousal.0.weight: Grad Norm = 0.0527\n",
            "shared_fc_arousal.0.bias: Grad Norm = 0.0053\n",
            "shared_fc_arousal.1.weight: Grad Norm = 0.0032\n",
            "shared_fc_arousal.1.bias: Grad Norm = 0.0033\n",
            "shared_fc_dominance.0.weight: Grad Norm = 0.1190\n",
            "shared_fc_dominance.0.bias: Grad Norm = 0.0087\n",
            "shared_fc_dominance.1.weight: Grad Norm = 0.0111\n",
            "shared_fc_dominance.1.bias: Grad Norm = 0.0093\n",
            "output_branch_arousal.0.weight: Grad Norm = 0.0740\n",
            "output_branch_arousal.0.bias: Grad Norm = 0.0058\n",
            "output_branch_arousal.1.weight: Grad Norm = 0.0036\n",
            "output_branch_arousal.1.bias: Grad Norm = 0.0042\n",
            "output_branch_arousal.4.weight: Grad Norm = 0.1285\n",
            "output_branch_arousal.4.bias: Grad Norm = 0.0167\n",
            "output_branch_dominance.0.weight: Grad Norm = 0.2220\n",
            "output_branch_dominance.0.bias: Grad Norm = 0.0163\n",
            "output_branch_dominance.1.weight: Grad Norm = 0.0122\n",
            "output_branch_dominance.1.bias: Grad Norm = 0.0209\n",
            "output_branch_dominance.4.weight: Grad Norm = 0.6255\n",
            "output_branch_dominance.4.bias: Grad Norm = 0.0918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/15 [Train]: 100%|██████████| 1004/1004 [09:16<00:00,  1.80it/s, loss=0.1250, a_loss=0.1409, d_loss=0.1197]\n",
            "Epoch 15/15 [Val]: 100%|██████████| 126/126 [00:45<00:00,  2.79it/s, loss=0.2454, a_loss=0.1459, d_loss=0.3449]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/15 Results:\n",
            "  Train Loss: 0.1570 (Arousal: 0.1185, Dominance: 0.1698)\n",
            "  Val Loss: 0.1363 (Arousal: 0.0996, Dominance: 0.1730)\n",
            "  Loss Weights - Arousal: 0.2500, Dominance: 0.7500\n",
            "  Saved best model (val_loss: 0.1363)\n",
            "\n",
            "Test Results:\n",
            "  Overall Test Loss: 0.1360\n",
            "  Arousal MSE: 0.1046, PCC: 0.7292\n",
            "  Dominance MSE: 0.1675, PCC: 0.6229\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel, BertTokenizer, HubertModel, Wav2Vec2FeatureExtractor\n",
        "import torchaudio\n",
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# ValenceRegressor\n",
        "class ValenceRegressor(nn.Module):\n",
        "    def __init__(self, audio_dim=768, text_dim=768, hidden_dim=192, num_heads=6, num_layers=2, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.audio_transformer = nn.ModuleList([\n",
        "            nn.TransformerEncoderLayer(d_model=audio_dim, nhead=num_heads, dim_feedforward=hidden_dim*4, dropout=dropout, batch_first=True)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "        self.audio_layer_norm = nn.LayerNorm(audio_dim)\n",
        "        self.audio_attention_pool = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim*2), nn.GELU(), nn.Dropout(dropout), nn.Linear(hidden_dim*2, 1)\n",
        "        )\n",
        "        self.text_encoder = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "        for param in self.text_encoder.parameters():\n",
        "            param.requires_grad = False\n",
        "        for param in list(self.text_encoder.parameters())[-2:]:\n",
        "            param.requires_grad = True\n",
        "        self.audio_projection = nn.Linear(audio_dim, hidden_dim)\n",
        "        self.text_projection = nn.Linear(text_dim, hidden_dim)\n",
        "        self.audio_to_text_attention = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=num_heads//2, dropout=dropout, batch_first=True)\n",
        "        self.text_to_audio_attention = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=num_heads//2, dropout=dropout, batch_first=True)\n",
        "        self.audio_gate = nn.Sequential(nn.Linear(hidden_dim*2, hidden_dim), nn.Sigmoid())\n",
        "        self.text_gate = nn.Sequential(nn.Linear(hidden_dim*2, hidden_dim), nn.Sigmoid())\n",
        "        self.fusion_layer = nn.Sequential(\n",
        "            nn.Linear(hidden_dim*2, hidden_dim*2), nn.LayerNorm(hidden_dim*2), nn.GELU(), nn.Dropout(dropout), nn.Linear(hidden_dim*2, hidden_dim)\n",
        "        )\n",
        "        self.shared_fc = nn.Sequential(nn.Linear(hidden_dim, hidden_dim), nn.LayerNorm(hidden_dim), nn.GELU(), nn.Dropout(dropout))\n",
        "        self.output_branch = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim//2), nn.LayerNorm(hidden_dim//2), nn.GELU(), nn.Dropout(dropout*0.5), nn.Linear(hidden_dim//2, 1)\n",
        "        )\n",
        "\n",
        "    def audio_attention_pooling(self, x, audio_mask=None):\n",
        "        weights = self.audio_attention_pool(x)\n",
        "        if audio_mask is not None:\n",
        "            weights = weights.masked_fill(~audio_mask.bool().unsqueeze(-1), float('-inf'))\n",
        "        weights = torch.softmax(weights, dim=1)\n",
        "        output = torch.bmm(weights.transpose(1, 2), x)\n",
        "        return output.squeeze(1)\n",
        "\n",
        "    def forward(self, audio_features, input_ids, attention_mask):\n",
        "        audio_mask = (audio_features.abs().sum(dim=-1) > 1e-6)\n",
        "        audio_repr = audio_features\n",
        "        for layer in self.audio_transformer:\n",
        "            audio_key_padding_mask = (~audio_mask).float()\n",
        "            audio_repr = layer(audio_repr, src_key_padding_mask=audio_key_padding_mask)\n",
        "        audio_repr = self.audio_layer_norm(audio_repr)\n",
        "        text_outputs = self.text_encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        text_repr = text_outputs.last_hidden_state\n",
        "        audio_proj = self.audio_projection(audio_repr)\n",
        "        text_proj = self.text_projection(text_repr)\n",
        "        audio_attended_text, _ = self.audio_to_text_attention(\n",
        "            query=audio_proj, key=text_proj, value=text_proj, key_padding_mask=(1 - attention_mask).bool()\n",
        "        )\n",
        "        text_attended_audio, _ = self.text_to_audio_attention(\n",
        "            query=text_proj, key=audio_proj, value=audio_proj, key_padding_mask=(~audio_mask).bool()\n",
        "        )\n",
        "        audio_concat = torch.cat([audio_proj, audio_attended_text], dim=-1)\n",
        "        text_concat = torch.cat([text_proj, text_attended_audio], dim=-1)\n",
        "        audio_gate_value = self.audio_gate(audio_concat)\n",
        "        text_gate_value = self.text_gate(text_concat)\n",
        "        gated_audio = audio_proj * audio_gate_value\n",
        "        gated_text = text_proj * text_gate_value\n",
        "        pooled_audio = self.audio_attention_pooling(gated_audio, audio_mask)\n",
        "        text_sum = torch.sum(gated_text * attention_mask.unsqueeze(-1), dim=1)\n",
        "        text_count = torch.sum(attention_mask, dim=1, keepdim=True).clamp(min=1)\n",
        "        pooled_text = text_sum / text_count\n",
        "        fused = torch.cat([pooled_audio, pooled_text], dim=1)\n",
        "        joint_repr = self.fusion_layer(fused)\n",
        "        shared = self.shared_fc(joint_repr)\n",
        "        output = self.output_branch(shared)\n",
        "        scaled_output = 1.0 + 4.0 * torch.sigmoid(output)\n",
        "        return scaled_output\n",
        "\n",
        "# MultimodalArousalDominanceModel\n",
        "class MultimodalArousalDominanceModel(nn.Module):\n",
        "    def __init__(self, audio_dim=768, text_dim=768, hidden_dim=192, num_heads=6, num_layers=2, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.audio_transformer = nn.ModuleList([\n",
        "            nn.TransformerEncoderLayer(d_model=audio_dim, nhead=num_heads, dim_feedforward=hidden_dim*4, dropout=dropout, batch_first=True)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "        self.audio_layer_norm = nn.LayerNorm(audio_dim)\n",
        "        self.audio_attention_pool = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim*2), nn.GELU(), nn.Dropout(dropout), nn.Linear(hidden_dim*2, 1)\n",
        "        )\n",
        "        self.text_encoder = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "        for param in self.text_encoder.parameters():\n",
        "            param.requires_grad = False\n",
        "        for param in list(self.text_encoder.parameters())[-2:]:\n",
        "            param.requires_grad = True\n",
        "        self.audio_projection = nn.Linear(audio_dim, hidden_dim)\n",
        "        self.text_projection = nn.Linear(text_dim, hidden_dim)\n",
        "        self.audio_to_text_attention = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=num_heads//2, dropout=dropout, batch_first=True)\n",
        "        self.text_to_audio_attention = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=num_heads//2, dropout=dropout, batch_first=True)\n",
        "        self.audio_gate = nn.Sequential(nn.Linear(hidden_dim*2, hidden_dim), nn.Sigmoid())\n",
        "        self.text_gate = nn.Sequential(nn.Linear(hidden_dim*2, hidden_dim), nn.Sigmoid())\n",
        "        self.fusion_layer_arousal = nn.Sequential(\n",
        "            nn.Linear(hidden_dim*2, hidden_dim*2), nn.LayerNorm(hidden_dim*2), nn.GELU(), nn.Dropout(dropout), nn.Linear(hidden_dim*2, hidden_dim)\n",
        "        )\n",
        "        self.fusion_layer_dominance = nn.Sequential(\n",
        "            nn.Linear(hidden_dim*2, hidden_dim*2), nn.LayerNorm(hidden_dim*2), nn.GELU(), nn.Dropout(dropout), nn.Linear(hidden_dim*2, hidden_dim)\n",
        "        )\n",
        "        self.shared_fc_arousal = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim), nn.LayerNorm(hidden_dim), nn.GELU(), nn.Dropout(dropout)\n",
        "        )\n",
        "        self.shared_fc_dominance = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim), nn.LayerNorm(hidden_dim), nn.GELU(), nn.Dropout(dropout)\n",
        "        )\n",
        "        self.output_branch_arousal = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim//2), nn.LayerNorm(hidden_dim//2), nn.GELU(), nn.Dropout(dropout*0.5), nn.Linear(hidden_dim//2, 1)\n",
        "        )\n",
        "        self.output_branch_dominance = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim//2), nn.LayerNorm(hidden_dim//2), nn.GELU(), nn.Dropout(dropout*0.5), nn.Linear(hidden_dim//2, 1)\n",
        "        )\n",
        "\n",
        "    def audio_attention_pooling(self, x, audio_mask=None):\n",
        "        weights = self.audio_attention_pool(x)\n",
        "        if audio_mask is not None:\n",
        "            weights = weights.masked_fill(~audio_mask.bool().unsqueeze(-1), float('-inf'))\n",
        "        weights = torch.softmax(weights, dim=1)\n",
        "        output = torch.bmm(weights.transpose(1, 2), x)\n",
        "        return output.squeeze(1)\n",
        "\n",
        "    def forward(self, audio_features, input_ids, attention_mask):\n",
        "        audio_mask = (audio_features.abs().sum(dim=-1) > 1e-6)\n",
        "        audio_repr = audio_features\n",
        "        for layer in self.audio_transformer:\n",
        "            audio_key_padding_mask = (~audio_mask).float()\n",
        "            audio_repr = layer(audio_repr, src_key_padding_mask=audio_key_padding_mask)\n",
        "        audio_repr = self.audio_layer_norm(audio_repr)\n",
        "        text_outputs = self.text_encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        text_repr = text_outputs.last_hidden_state\n",
        "        audio_proj = self.audio_projection(audio_repr)\n",
        "        text_proj = self.text_projection(text_repr)\n",
        "        audio_attended_text, _ = self.audio_to_text_attention(\n",
        "            query=audio_proj, key=text_proj, value=text_proj, key_padding_mask=(1 - attention_mask).bool()\n",
        "        )\n",
        "        text_attended_audio, _ = self.text_to_audio_attention(\n",
        "            query=text_proj, key=audio_proj, value=audio_proj, key_padding_mask=(~audio_mask).bool()\n",
        "        )\n",
        "        audio_concat = torch.cat([audio_proj, audio_attended_text], dim=-1)\n",
        "        text_concat = torch.cat([text_proj, text_attended_audio], dim=-1)\n",
        "        audio_gate_value = self.audio_gate(audio_concat)\n",
        "        text_gate_value = self.text_gate(text_concat)\n",
        "        gated_audio = audio_proj * audio_gate_value\n",
        "        gated_text = text_proj * text_gate_value\n",
        "        pooled_audio = self.audio_attention_pooling(gated_audio, audio_mask)\n",
        "        text_sum = torch.sum(gated_text * attention_mask.unsqueeze(-1), dim=1)\n",
        "        text_count = torch.sum(attention_mask, dim=1, keepdim=True).clamp(min=1)\n",
        "        pooled_text = text_sum / text_count\n",
        "        fused = torch.cat([pooled_audio, pooled_text], dim=1)\n",
        "        joint_repr_arousal = self.fusion_layer_arousal(fused)\n",
        "        joint_repr_dominance = self.fusion_layer_dominance(fused)\n",
        "        shared_arousal = self.shared_fc_arousal(joint_repr_arousal)\n",
        "        shared_dominance = self.shared_fc_dominance(joint_repr_dominance)\n",
        "        output_arousal = self.output_branch_arousal(shared_arousal)\n",
        "        output_dominance = self.output_branch_dominance(shared_dominance)\n",
        "        scaled_arousal = 1.0 + 4.0 * torch.sigmoid(output_arousal)\n",
        "        scaled_dominance = 1.0 + 4.0 * torch.sigmoid(output_dominance)\n",
        "        return scaled_arousal, scaled_dominance\n",
        "\n",
        "# Function to clear Hugging Face cache\n",
        "def clear_huggingface_cache():\n",
        "    cache_dir = Path.home() / \".cache\" / \"huggingface\" / \"transformers\"\n",
        "    if cache_dir.exists():\n",
        "        shutil.rmtree(cache_dir)\n",
        "        print(f\"Cleared cache at {cache_dir}\")\n",
        "\n",
        "# Function to load feature extractor with retry\n",
        "def load_feature_extractor(model_name, max_retries=3):\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            return Wav2Vec2FeatureExtractor.from_pretrained(model_name)\n",
        "        except (OSError, ValueError) as e:\n",
        "            print(f\"Attempt {attempt+1}/{max_retries} failed: {e}\")\n",
        "            if attempt < max_retries - 1:\n",
        "                clear_huggingface_cache()\n",
        "    raise RuntimeError(f\"Failed to load Wav2Vec2FeatureExtractor after {max_retries} attempts\")\n",
        "\n",
        "# Function to extract audio features using HuBERT\n",
        "def extract_hubert_features(audio_path, processor, hubert_model, device, sampling_rate=16000, max_audio_samples=128000):\n",
        "    audio, sr = torchaudio.load(audio_path)\n",
        "    if sr != sampling_rate:\n",
        "        audio = torchaudio.transforms.Resample(sr, sampling_rate)(audio)\n",
        "    audio = audio.squeeze(0)\n",
        "    if audio.dim() > 1:\n",
        "        audio = audio[0]\n",
        "    if audio.size(0) > max_audio_samples:\n",
        "        audio = audio[:max_audio_samples]\n",
        "    elif audio.size(0) < max_audio_samples:\n",
        "        audio = torch.nn.functional.pad(audio, (0, max_audio_samples - audio.size(0)))\n",
        "    audio = audio.cpu().numpy()\n",
        "    inputs = processor(audio, sampling_rate=sampling_rate, return_tensors=\"pt\", padding=False, truncation=False)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = hubert_model(**inputs)\n",
        "    return outputs.last_hidden_state\n",
        "\n",
        "# Function to preprocess inputs\n",
        "def preprocess_inputs(text, audio_path, tokenizer, processor, hubert_model, device, max_length=512):\n",
        "    encoding = tokenizer(text, max_length=max_length, padding='max_length', truncation=True, return_tensors='pt')\n",
        "    input_ids = encoding['input_ids'].to(device)\n",
        "    attention_mask = encoding['attention_mask'].to(device)\n",
        "    audio_features = extract_hubert_features(audio_path, processor, hubert_model, device)\n",
        "    return input_ids, attention_mask, audio_features\n",
        "\n",
        "# Function to load models\n",
        "def load_models(valence_checkpoint_path, ad_checkpoint_path, device):\n",
        "    valence_model = ValenceRegressor(audio_dim=768, text_dim=768, hidden_dim=192, num_heads=6, num_layers=2, dropout=0.5)\n",
        "    valence_checkpoint = torch.load(valence_checkpoint_path, map_location=device)\n",
        "    valence_model.load_state_dict(valence_checkpoint['model_state_dict'])\n",
        "    if torch.cuda.device_count() > 1:\n",
        "        valence_model = nn.DataParallel(valence_model)\n",
        "    valence_model.to(device)\n",
        "    valence_model.eval()\n",
        "\n",
        "    ad_model = MultimodalArousalDominanceModel(audio_dim=768, text_dim=768, hidden_dim=192, num_heads=6, num_layers=2, dropout=0.5)\n",
        "    ad_checkpoint = torch.load(ad_checkpoint_path, map_location=device)\n",
        "    ad_model.load_state_dict(ad_checkpoint['model_state_dict'])\n",
        "    if torch.cuda.device_count() > 1:\n",
        "        ad_model = nn.DataParallel(ad_model)\n",
        "    ad_model.to(device)\n",
        "    ad_model.eval()\n",
        "\n",
        "    return valence_model, ad_model\n",
        "\n",
        "# Main function for prediction\n",
        "def predict_emotions(audio_path, transcription, valence_checkpoint_path, ad_checkpoint_path):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "    processor = load_feature_extractor('facebook/hubert-base-ls960')\n",
        "    hubert_model = HubertModel.from_pretrained('facebook/hubert-base-ls960').to(device)\n",
        "    hubert_model.eval()\n",
        "\n",
        "    valence_model, ad_model = load_models(valence_checkpoint_path, ad_checkpoint_path, device)\n",
        "\n",
        "    input_ids, attention_mask, audio_features = preprocess_inputs(\n",
        "        text=transcription,\n",
        "        audio_path=audio_path,\n",
        "        tokenizer=tokenizer,\n",
        "        processor=processor,\n",
        "        hubert_model=hubert_model,\n",
        "        device=device,\n",
        "        max_length=512\n",
        "    )\n",
        "\n",
        "    with torch.no_grad():\n",
        "        valence_pred = valence_model(audio_features, input_ids, attention_mask)\n",
        "        arousal_pred, dominance_pred = ad_model(audio_features, input_ids, attention_mask)\n",
        "\n",
        "    return {\n",
        "        'valence': valence_pred.item(),\n",
        "        'arousal': arousal_pred.item(),\n",
        "        'dominance': dominance_pred.item()\n",
        "    }\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    valence_checkpoint_path = 'path/to/valence_model_checkpoint.pth'  # Replace\n",
        "    ad_checkpoint_path = '/content/best_arousal_dominance_model.pth'\n",
        "    audio_path = 'path/to/audio.wav'  # Replace\n",
        "    transcription = \"This is a sample utterance from IEMOCAP.\"\n",
        "\n",
        "    predictions = predict_emotions(audio_path, transcription, valence_checkpoint_path, ad_checkpoint_path)\n",
        "\n",
        "    print(f\"Predicted Valence: {predictions['valence']:.4f}\")\n",
        "    print(f\"Predicted Arousal: {predictions['arousal']:.4f}\")\n",
        "    print(f\"Predicted Dominance: {predictions['dominance']:.4f}\")"
      ],
      "metadata": {
        "id": "O-J-VlAtgBcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YBPe-EdygE4v"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}